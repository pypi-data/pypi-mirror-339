{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing run logs, metrics and cost\n",
    "\n",
    "This notebook will help us to explore logs and checkpoints generated during training. \n",
    "\n",
    "Some of the logging is optional, especially during full scale training runs. All logs are synced with a version naming convention in order to facilitate easy retrieval of a specific run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpts = os.listdir(\"../checkpoints\")\n",
    "lightning_logs = os.listdir(\"../logs/lightning_logs\")\n",
    "perf_logs = os.listdir(\"../logs/perf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpoints are .ckpt files that hold the model weights. To use these files, we can load them directly into our custom LightningModules with [.load_from_checkpoint](https://lightning.ai/docs/pytorch/stable/common/checkpointing_basic.html#lightningmodule-from-checkpoint).\n",
    "\n",
    "Here are our available checkpoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch Lightning integrates with several experiment managers to log training metrics. My personal favorite, and perhaps the simplest to use to enable custom visualizations, is [CSVLogger](https://lightning.ai/docs/pytorch/stable/extensions/generated/lightning.pytorch.loggers.CSVLogger.html).\n",
    "\n",
    "The logs saved during training runs are shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['google_bert_uncased_L-8_H-512_A-8_Tesla T4_LR3e-05_BS64_ML256_2025-03-31T14_28_33.351315',\n",
       " 'google_bert_uncased_L-4_H-512_A-8_Tesla T4_LR3e-05_BS64_ML256_2025-03-31T14_03_54.835687',\n",
       " 'google_bert_uncased_L-12_H-768_A-12_Tesla T4_LR3e-05_BS64_ML256_2025-03-31T15_13_11.277592']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lightning_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get a basic sense of training times, there exists a `log_perf` function in `utils.py`. Using `log_perf` saves a simple json file with some basic metrics on the training run â€“ notably, the CPU or GPU type, and the amount of time it took to complete a minimum number of epochs. \n",
    "\n",
    "These files were created by passing the `--perf` flag to `trainer.py` with\n",
    "\n",
    "```sh\n",
    "python trainer.py --perf=True\n",
    "```\n",
    "\n",
    "Doing the above will run your Trainer and time the run. This can help to determine which machine to use before initiating a longer run. \n",
    "\n",
    "Logs for the example runs are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['google_bert_uncased_L-8_H-512_A-8_Tesla T4_LR3e-05_BS64_ML256_2025-03-31T14_28_33.351315.json',\n",
       " 'google_bert_uncased_L-4_H-512_A-8_Tesla T4_LR3e-05_BS64_ML256_2025-03-31T14_03_54.835687.json']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining training times\n",
    "\n",
    "First, let's read in the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_name</th>\n",
       "      <th>num_node</th>\n",
       "      <th>num_devices:</th>\n",
       "      <th>strategy</th>\n",
       "      <th>precision</th>\n",
       "      <th>epochs</th>\n",
       "      <th>global_step</th>\n",
       "      <th>max_epochs</th>\n",
       "      <th>min_epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>runtime_min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>google_bert_uncased_L-4_H-512_A-8_Tesla T4_LR3e-05_BS64_ML256_2025-03-31T14_03_54.835687.json</th>\n",
       "      <td>Tesla T4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SingleDeviceStrategy</td>\n",
       "      <td>16-mixed</td>\n",
       "      <td>5</td>\n",
       "      <td>10600</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>24.438696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google_bert_uncased_L-8_H-512_A-8_Tesla T4_LR3e-05_BS64_ML256_2025-03-31T14_28_33.351315.json</th>\n",
       "      <td>Tesla T4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SingleDeviceStrategy</td>\n",
       "      <td>16-mixed</td>\n",
       "      <td>5</td>\n",
       "      <td>10600</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>44.514956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   device_name  num_node  \\\n",
       "run                                                                        \n",
       "google_bert_uncased_L-4_H-512_A-8_Tesla T4_LR3e...    Tesla T4         1   \n",
       "google_bert_uncased_L-8_H-512_A-8_Tesla T4_LR3e...    Tesla T4         1   \n",
       "\n",
       "                                                    num_devices:  \\\n",
       "run                                                                \n",
       "google_bert_uncased_L-4_H-512_A-8_Tesla T4_LR3e...             1   \n",
       "google_bert_uncased_L-8_H-512_A-8_Tesla T4_LR3e...             1   \n",
       "\n",
       "                                                                strategy  \\\n",
       "run                                                                        \n",
       "google_bert_uncased_L-4_H-512_A-8_Tesla T4_LR3e...  SingleDeviceStrategy   \n",
       "google_bert_uncased_L-8_H-512_A-8_Tesla T4_LR3e...  SingleDeviceStrategy   \n",
       "\n",
       "                                                   precision  epochs  \\\n",
       "run                                                                    \n",
       "google_bert_uncased_L-4_H-512_A-8_Tesla T4_LR3e...  16-mixed       5   \n",
       "google_bert_uncased_L-8_H-512_A-8_Tesla T4_LR3e...  16-mixed       5   \n",
       "\n",
       "                                                    global_step  max_epochs  \\\n",
       "run                                                                           \n",
       "google_bert_uncased_L-4_H-512_A-8_Tesla T4_LR3e...        10600           5   \n",
       "google_bert_uncased_L-8_H-512_A-8_Tesla T4_LR3e...        10600           5   \n",
       "\n",
       "                                                    min_epochs  batch_size  \\\n",
       "run                                                                          \n",
       "google_bert_uncased_L-4_H-512_A-8_Tesla T4_LR3e...           0          64   \n",
       "google_bert_uncased_L-8_H-512_A-8_Tesla T4_LR3e...           0          64   \n",
       "\n",
       "                                                    runtime_min  \n",
       "run                                                              \n",
       "google_bert_uncased_L-4_H-512_A-8_Tesla T4_LR3e...    24.438696  \n",
       "google_bert_uncased_L-8_H-512_A-8_Tesla T4_LR3e...    44.514956  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_perfs = []\n",
    "\n",
    "for run in perf_logs:\n",
    "    with open(f\"../logs/perf/{run}\", 'r') as f:\n",
    "        data = json.load(f)\n",
    "        data['perf']['run'] = run\n",
    "        all_perfs.append(data['perf'])\n",
    "    \n",
    "perf_df = pd.DataFrame(all_perfs)\n",
    "perf_df.set_index(\"run\", inplace=True)\n",
    "perf_df.sort_values(\"runtime_min\", inplace=True)\n",
    "perf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then, we can find the model with the minimum training time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'perf_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m best_run_perf = \u001b[43mperf_df\u001b[49m.iloc[\u001b[32m0\u001b[39m]\n\u001b[32m      2\u001b[39m display(best_run_perf)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe run with the fastest training time used the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_run_perf[\u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m model and a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_run_perf[\u001b[33m'\u001b[39m\u001b[33mdevice_name\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m device.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'perf_df' is not defined"
     ]
    }
   ],
   "source": [
    "best_run_perf = perf_df.iloc[0]\n",
    "display(best_run_perf)\n",
    "\n",
    "print(f\"The run with the fastest training time used the {best_run_perf['model']} model and a {best_run_perf['device_name']} device.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
