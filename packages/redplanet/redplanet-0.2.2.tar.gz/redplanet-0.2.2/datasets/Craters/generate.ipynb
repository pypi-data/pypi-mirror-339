{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# [0] Imports / Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from redplanet.DatasetManager.hash import _calculate_hash_from_file, get_available_algorithms\n",
    "from redplanet.DatasetManager.download import _download_file_from_url\n",
    "from redplanet.helper_functions.coordinates import _plon2slon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_table(data):\n",
    "    if not data:\n",
    "        return\n",
    "\n",
    "    num_columns = max(len(row) for row in data)\n",
    "    max_widths = [0] * num_columns\n",
    "\n",
    "    ## compute max widths for each column\n",
    "    for j in range(num_columns):\n",
    "        column_values = [str(row[j]) if j < len(row) else '' for row in data]\n",
    "        max_widths[j] = max(len(value) for value in column_values)\n",
    "\n",
    "    ## print rows\n",
    "    for row in data:\n",
    "        for j in range(num_columns):\n",
    "            value = str(row[j]) if j < len(row) else ''\n",
    "            print(value.ljust(max_widths[j]), end='    ')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''NOTE: set this according to your own system'''\n",
    "dirpath_cwd = Path('/home/lain/root/100_work/110_projects/111_mars/code-repos/redplanet/datasets/Craters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''see readme'''\n",
    "\n",
    "download_info = {\n",
    "    'crater_ages': {\n",
    "        # see Supplementary Table 3 of https://doi.org/10.1016/j.icarus.2013.03.019\n",
    "        'fname' : 'Table 3.tex',\n",
    "        'url'   : 'https://rutgers.box.com/shared/static/fdk83g5g5pn2kltrqodvwnvmvjbmggzh',\n",
    "        'sha256': 'f81bf35ba76f0f2e9939d7a338084451145cdc8d9771124ac4e8ec71802ea236',\n",
    "    },\n",
    "    'crater_database': {\n",
    "        # https://craters.sjrdesign.net/\n",
    "        'fname' : 'Catalog_Mars_Release_2020_1kmPlus_FullMorphData.csv',\n",
    "        'url'   : 'https://rutgers.box.com/shared/static/sry0fof5brqu9pz2tfk6xfix7c3w1xyu',\n",
    "        'sha256': '348e5b88912e6e67b71fb4afffc8f76a170524e1308c171f98c805c045813c22',\n",
    "    },\n",
    "    'crater_names': {\n",
    "        # https://planetarynames.wr.usgs.gov/SearchResults?Target=20_Mars&Feature%20Type=9_Crater,%20craters\n",
    "        'fname' : 'IAU-crater-names_as-of_2024-11-26.csv',\n",
    "        'url'   : 'https://rutgers.box.com/shared/static/xjljza4gw9743dutlpez8m8ccgmkzfnd',\n",
    "        'sha256': '4c08fe5c2477d20ffdd088d45275fb1469fd2970900aa5b9aeff66160285a5ea',\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def temp_download(key):\n",
    "    \"\"\"context manager for downloading and cleaning up a temporary file.\"\"\"\n",
    "    metadata = download_info[key]\n",
    "\n",
    "    dirpath_intermediate = dirpath_cwd / 'intermediate'\n",
    "    dirpath_intermediate.mkdir(exist_ok=True, parents=True)\n",
    "    fpath = dirpath_intermediate / metadata['fname']\n",
    "\n",
    "    try:\n",
    "        if not fpath.exists():\n",
    "            _download_file_from_url(metadata['url'], fpath)\n",
    "\n",
    "        computed_hash = _calculate_hash_from_file(fpath, 'sha256')\n",
    "\n",
    "        if computed_hash != metadata['sha256']:\n",
    "            error_msg = [\n",
    "                f'hash mismatch:',\n",
    "                f'- expected hash: {metadata[\"sha256\"]}',\n",
    "                f'- computed hash: {computed_hash}',\n",
    "            ]\n",
    "            raise ValueError('\\n'.join(error_msg))\n",
    "\n",
    "        yield fpath    ## yield the file path for use in the `with` block\n",
    "\n",
    "    finally:\n",
    "        # if fpath.exists():\n",
    "        #     fpath.unlink()\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# [1] Read: Robbins 2013 crater ages  _(latex -> pandas)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with temp_download('crater_ages') as fpath:\n",
    "    with fpath.open('r') as f:\n",
    "        dat = f.readlines()\n",
    "\n",
    "\n",
    "\n",
    "'''read only the table data'''\n",
    "dat = dat[11:12] + dat[15:-6]\n",
    "del dat[25]  # remove comment\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''format/parse'''\n",
    "newdat = []\n",
    "for row in dat:\n",
    "    row = row.replace('\\\\\\\\', '')\n",
    "    row = row.strip()\n",
    "    row = row.split('&')\n",
    "\n",
    "    newrow = []\n",
    "\n",
    "    for item in row:\n",
    "\n",
    "        item = item.strip()\n",
    "\n",
    "        ## get rid of latex inline math\n",
    "        if item.startswith('$') and item.endswith('$'):\n",
    "            item = item[1:-1]\n",
    "            item = item.strip()\n",
    "\n",
    "        ## for \"Name\" values like \"\\gamma\"\n",
    "        if item.startswith('\\\\'):\n",
    "            item = item[1:]\n",
    "            item = item.strip()\n",
    "\n",
    "        ## convert an age like `3.93_{-0.08}^{+0.05 }` to `3.93,-0.08,0.05`\n",
    "        if ('_{' in item) and ('^{' in item):\n",
    "            item = item.split('{')\n",
    "            numbers = []\n",
    "            for n in item:\n",
    "                n = re.sub(r'[^0-9.\\-]', '', n)\n",
    "                numbers.append(n)\n",
    "            item = ';'.join(numbers)\n",
    "\n",
    "        ## convert numerics\n",
    "        try:\n",
    "            item = float(item)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        # ## verify all ages have been converted properly\n",
    "        # if '^' in item:\n",
    "        #     print(item)\n",
    "\n",
    "        newrow.append(item)\n",
    "\n",
    "    newdat.append(newrow)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''convert to dataframe and cleanup types'''\n",
    "\n",
    "cols = {\n",
    "    'Name'           : 'name',\n",
    "    'Diameter (km)'  : 'diam',\n",
    "    'Latitude'       : 'lat',\n",
    "    'Longitude'      : 'lon',\n",
    "    'N_{\\rm{H}}(10)' : 'N_H(10)',\n",
    "    'N_{\\rm{N}}(10)' : 'N_N(10)',\n",
    "    'N_{\\rm{H}}(25)' : 'N_H(25)',\n",
    "    'N_{\\rm{N}}(25)' : 'N_N(25)',\n",
    "    'N_{\\rm{H}}(50)' : 'N_H(50)',\n",
    "    'N_{\\rm{N}}(50)' : 'N_N(50)',\n",
    "    'Hartmann Isochron Age (Ga)'      : 'Hartmann Isochron Age',\n",
    "    'Neukum Isochron Age (Ga)'        : 'Neukum Isochron Age',\n",
    "    'Hartmann Turn-Off Diameter (km)' : 'Hartmann Turn-Off Diameter',\n",
    "    'Neukum Turn-Off Diameter (km)'   : 'Neukum Turn-Off Diameter',\n",
    "}\n",
    "\n",
    "df_ages = pd.DataFrame(\n",
    "    newdat[1:],\n",
    "    columns = list(cols.keys())\n",
    ")\n",
    "df_ages.rename(columns=cols, inplace=True)\n",
    "\n",
    "\n",
    "## strings\n",
    "df_ages = df_ages.convert_dtypes()\n",
    "df_ages = df_ages.replace('', pd.NA)\n",
    "\n",
    "\n",
    "## numerics\n",
    "numeric_cols = [\n",
    "    'diam',\n",
    "    'lat',\n",
    "    'lon',\n",
    "    'Hartmann Turn-Off Diameter',\n",
    "    'Neukum Turn-Off Diameter',\n",
    "\n",
    "]\n",
    "for col in numeric_cols:\n",
    "    df_ages[col] = pd.to_numeric(df_ages[col], errors='coerce')\n",
    "\n",
    "df_ages['lon'] = df_ages['lon'].apply(_plon2slon)\n",
    "\n",
    "## lol what is this spelling\n",
    "df_ages.loc[df_ages['name'] == 'Bacquerel', 'name'] = 'Becquerel'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''print/display'''\n",
    "# print(df_ages.dtypes)\n",
    "df_ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ages.query('name == \"Henry\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_ages[ pd.notna(df_ages['Hartmann Isochron Age']) ].shape[0]\n",
    "\n",
    "print(f'resolvable ages for {x} craters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# [2] Read: Robbins 2020 crater database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: for now only keep lon/lat for easy working purposes, but later on merge elliptical stuff based on crater id\n",
    "cols = {\n",
    "    'CRATER_ID'              : 'id',\n",
    "    'LAT_CIRC_IMG'           : 'lat',\n",
    "    'LON_CIRC_IMG'           : 'lon',\n",
    "    # 'LAT_ELLI_IMG'           : 'lat_elli',\n",
    "    # 'LON_ELLI_IMG'           : 'lon_elli',\n",
    "    'DIAM_CIRC_IMG'          : 'diam',\n",
    "    'DIAM_CIRC_SD_IMG'       : 'diam_sd',\n",
    "    'DIAM_ELLI_MAJOR_IMG'    : 'diam_elli_major',\n",
    "    'DIAM_ELLI_MINOR_IMG'    : 'diam_elli_minor',\n",
    "    # 'DIAM_ELLI_ECCEN_IMG'    : 'diam_elli_eccen',\n",
    "    # 'DIAM_ELLI_ELLIP_IMG'    : 'diam_elli_ellip',\n",
    "    'DIAM_ELLI_ANGLE_IMG'    : 'diam_elli_angle',\n",
    "    ## normally i ignore everything past this point...\n",
    "    # 'LAT_ELLI_SD_IMG'        : ...,\n",
    "    # 'LON_ELLI_SD_IMG'        : ...,\n",
    "    'DIAM_ELLI_MAJOR_SD_IMG' : 'diam_elli_major_sd',\n",
    "    'DIAM_ELLI_MINOR_SD_IMG' : 'diam_elli_minor_sd',\n",
    "    # 'DIAM_ELLI_ANGLE_SD_IMG' : ...,\n",
    "    # 'DIAM_ELLI_ECCEN_SD_IMG' : ...,\n",
    "    # 'DIAM_ELLI_ELLIP_SD_IMG' : ...,\n",
    "    # 'ARC_IMG'                : ...,\n",
    "    # 'PTS_RIM_IMG'            : ...,\n",
    "    # 'LAY_NUMBER'             : ...,\n",
    "    # 'LAY_MORPH1'             : ...,\n",
    "    # 'LAY_MORPH2'             : ...,\n",
    "    # 'LAY_MORPH3'             : ...,\n",
    "    # 'LAY_NOTES'              : ...,\n",
    "    # 'INT_MORPH1'             : ...,\n",
    "    # 'INT_MORPH2'             : ...,\n",
    "    # 'INT_MORPH3'             : ...,\n",
    "    # 'CONF'                   : ...,\n",
    "    # 'NOTES'                  : ...,\n",
    "    # 'DEG_RIM'                : ...,\n",
    "    # 'DEG_EJC'                : ...,\n",
    "    # 'DEG_FLR'                : ...,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "with temp_download('crater_database') as fpath:\n",
    "    df_20 = pd.read_csv(\n",
    "        fpath,\n",
    "        header  = 0,\n",
    "        usecols = list(cols.keys())\n",
    "    )\n",
    "\n",
    "df_20.rename(columns=cols, inplace=True)\n",
    "\n",
    "df_20.sort_values('diam', ascending=False, ignore_index=True, inplace=True)\n",
    "\n",
    "min_diam = 50\n",
    "df_20 = df_20[df_20['diam'] >= min_diam]\n",
    "\n",
    "df_20.drop_duplicates(inplace=True)\n",
    "\n",
    "df_20['lon'] = df_20['lon'].apply(_plon2slon)\n",
    "\n",
    "df_20.insert(loc=1, column='name', value=pd.Series(dtype='string'))\n",
    "\n",
    "\n",
    "\n",
    "# print(df_20.dtypes)\n",
    "df_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lons = sorted(np.array((df_20['lon'].values)))\n",
    "print(f'lons: {lons[0]} -> {lons[-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lons: -179.9231989 -> 179.80030220000003"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# [3] Read: IAU crater names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = {\n",
    "    'Feature Name'              : 'name',\n",
    "    # 'Target'                    : '',    # all 'Mars'\n",
    "    'Diameter'                  : 'diam',\n",
    "    'Center Latitude'           : 'lat',\n",
    "    'Center          Longitude' : 'lon',\n",
    "    # 'Feature Type'              : '',    # all 'Crater, craters\n",
    "    # 'Approval Date'             : '',    # idc\n",
    "    # 'Origin'                    : '',    # idc\n",
    "}\n",
    "\n",
    "with temp_download('crater_names') as fpath:\n",
    "    df_names = pd.read_csv(\n",
    "        fpath,\n",
    "        header  = 0,\n",
    "        usecols = list(cols.keys()),\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "print(f'{df_names.shape[0]} entries initially')\n",
    "\n",
    "df_names.rename(columns=cols, inplace=True)\n",
    "\n",
    "df_names.sort_values('diam', ascending=False, ignore_index=True, inplace=True)\n",
    "\n",
    "min_diam = 50\n",
    "df_names = df_names[ df_names['diam'] >= min_diam ]\n",
    "\n",
    "print(f'({min_diam}km min diam cutoff)')\n",
    "print(f'{df_names.shape[0]} entries left')\n",
    "\n",
    "df_names['lon'] = df_names['lon'].apply(_plon2slon)\n",
    "\n",
    "df_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1218 entries initially\n",
    "\n",
    "(50km min diam cutoff)\n",
    "\n",
    "341 entries left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# [4] Merge names: df_names -> df_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_20_n = df_20.copy()\n",
    "\n",
    "\n",
    "coord_error = 0.3\n",
    "\n",
    "# diam_error  = 15\n",
    "diam_rel_error = 0.1\n",
    "\n",
    "diam_lessthan_ignore = 52\n",
    "\n",
    "\n",
    "\n",
    "'''merge names from iau to robbinsV20'''\n",
    "\n",
    "print(f'named craters: {df_names.shape[0]}\\n')\n",
    "\n",
    "print(f'ignoring named craters with D<{diam_lessthan_ignore}km: {df_names[df_names[\"diam\"] < diam_lessthan_ignore].shape[0]}\\n')\n",
    "\n",
    "\n",
    "messy_results = [['NUM_RESULTS', 'NAME', 'DIAM', 'LON', 'LAT']]\n",
    "\n",
    "for i, crater in df_names.iterrows():\n",
    "\n",
    "    ## ignore edge cases around 50km diam threshold\n",
    "    if crater['diam'] < diam_lessthan_ignore:\n",
    "        continue\n",
    "\n",
    "    search = df_20_n[\n",
    "        (df_20_n['lon' ].between( crater['lon'] - coord_error       , crater['lon'] + coord_error       )) &\n",
    "        (df_20_n['lat' ].between( crater['lat'] - coord_error       , crater['lat'] + coord_error       )) &\n",
    "        (df_20_n['diam'].between( crater['diam']*(1-diam_rel_error) , crater['diam']*(1+diam_rel_error) ))\n",
    "    ]\n",
    "\n",
    "    num_results = search.shape[0]\n",
    "\n",
    "    if num_results == 1:\n",
    "        df_20_n.loc[search.index, 'name'] = crater['name']\n",
    "    else:\n",
    "        messy_results.append([f'{num_results}', crater['name'], crater['diam'], crater['lon'], crater['lat']])\n",
    "\n",
    "\n",
    "\n",
    "print(f'added names: {df_20_n[\"name\"].notna().sum()}\\n')\n",
    "print(f'messy results: {len(messy_results) - 1}\\n')\n",
    "print_table(messy_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "named craters: 341\n",
    "\n",
    "ignoring named craters with D<52km: 20\n",
    "\n",
    "added names: 313\n",
    "\n",
    "messy results: 8\n",
    "\n",
    "NUM_RESULTS   | NAME           | DIAM     | LON                   | LAT       \n",
    "---           | ---            | ---      | ---                   | ---\n",
    "0             | Robert Sharp   | 152.08   | 133.41999999999996    | -4.17     \n",
    "0             | Roemer         | 120.0    | 8.090000000000003     | -27.46    \n",
    "0             | Barth          | 111.0    | 25.670000000000016    | 7.44      \n",
    "0             | Tycho Brahe    | 105.27   | 146.12                | -49.41    \n",
    "0             | Richardson     | 89.0     | -179.86               | -72.47    \n",
    "0             | Novara         | 86.98    | -10.689999999999998   | -24.9     \n",
    "0             | Elston         | 75.0     | 119.18                | -15.39    \n",
    "0             | Eberswalde     | 62.19    | -33.30000000000001    | -23.98    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''manually assign messy results'''\n",
    "\n",
    "already_exists = (\n",
    "    ('Roemer'     , '11-3-000193'),  ## reason: big diameter discrepancy && overlapping (not sure if distinct?)\n",
    "    ('Roemer'     , '11-0-002560'),  ## ^\n",
    "    ('Barth'      , '10-0-003400'),  ## reason: reasonable diameter discrepency\n",
    "    ('Tycho Brahe', '16-1-002468'),  ## reason: very elliptical\n",
    "    ('Richardson' , '16-1-009592'),  ## reason: lon wraparound\n",
    "    ('Novara'     , '07-0-002030'),  ## reason: very elliptical\n",
    "    ('Elston'     , '15-1-013698'),  ## reason: big diameter discrepancy && overlapping (not sure if distinct?)\n",
    "    ('Elston'     , '15-1-013699'),  ## ^\n",
    "    ('Eberswalde' , '07-1-015599'),  ## reason: very elliptical\n",
    "    ## NOTE: not assigning Robert Sharp bc i'm not sure if it's actually a crater: https://planetarynames.wr.usgs.gov/Feature/15002\n",
    ")\n",
    "\n",
    "for name, crater_id in already_exists:\n",
    "    df_20_n.loc[ df_20_n['id'] == crater_id, 'name' ] = name\n",
    "\n",
    "print(f'named craters in newly merged v20 dataset (not counting duplicates): {df_20_n[\"name\"].unique().shape[0] - 1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_20_n.query('name == \"Elston\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_20_n.query('name == \"Roemer\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# [5] Merge ages: df_ages -> df_20_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''init empty columns'''\n",
    "df_ages_cols_toinclude = [\n",
    "    # 'name',\n",
    "    # 'diam',\n",
    "    # 'lat',\n",
    "    # 'lon',\n",
    "    'N_H(10)',\n",
    "    'N_N(10)',\n",
    "    'N_H(25)',\n",
    "    'N_N(25)',\n",
    "    'N_H(50)',\n",
    "    'N_N(50)',\n",
    "    'Hartmann Isochron Age',\n",
    "    'Neukum Isochron Age',\n",
    "    'Hartmann Turn-Off Diameter',\n",
    "    'Neukum Turn-Off Diameter',\n",
    "]\n",
    "df_20_na = df_20_n.copy()\n",
    "for col in df_ages_cols_toinclude:\n",
    "    df_20_na[col] = pd.NA\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "coord_error = 1\n",
    "\n",
    "# diam_error  = 10\n",
    "diam_rel_error = 0.1\n",
    "\n",
    "\n",
    "\n",
    "'''merge names from iau to robbinsV20'''\n",
    "\n",
    "messy_results = [['NUM_RESULTS', 'NAME', 'DIAM', 'LON', 'LAT']]\n",
    "\n",
    "for i, crater in df_ages.iterrows():\n",
    "\n",
    "    search = df_20_na[\n",
    "        (df_20_na['lon' ].between( crater['lon'] - coord_error       , crater['lon'] + coord_error       )) &\n",
    "        (df_20_na['lat' ].between( crater['lat'] - coord_error       , crater['lat'] + coord_error       )) &\n",
    "        (df_20_na['diam'].between( crater['diam']*(1-diam_rel_error) , crater['diam']*(1+diam_rel_error) ))\n",
    "    ]\n",
    "    num_results = search.shape[0]\n",
    "\n",
    "    if num_results == 1:\n",
    "        df_20_na.loc[search.index, df_ages_cols_toinclude] = crater[df_ages_cols_toinclude].values\n",
    "\n",
    "    else:\n",
    "        messy_results.append([f'{num_results}', crater['name'], crater['diam'], crater['lon'], crater['lat']])\n",
    "\n",
    "\n",
    "print(f'messy results: {len(messy_results) - 1}\\n')\n",
    "print_table(messy_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't care about $\\nu$ ('nu') crater, the Robbins age table gives zero info (ages/densities) besides the coords/diameter lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'num craters with resolved ages: {df_20_na[ pd.notna(df_20_na[\"Hartmann Isochron Age\"]) ].shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath_out = dirpath_cwd / 'output'\n",
    "Path.mkdir(dirpath_out, exist_ok=True)\n",
    "fpath_out = dirpath_out / 'craters_with_names_and_ages_50km.csv'\n",
    "\n",
    "df_20_na.to_csv(fpath_out, index=False)\n",
    "\n",
    "df = pd.read_csv(fpath_out)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alg in get_available_algorithms():\n",
    "    print(f'{alg}: {_calculate_hash_from_file(fpath_out, alg)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- xxh3_64: ea14d77f25f090c4\n",
    "- md5: 4e63fd2a7f1367d131ee606edcdfb5f7\n",
    "- sha1: 79113d236836e1d8bb53e517ab3cfc4afad2cac2\n",
    "- sha256: e48808ef670e39e812149e4731634d59964b7b3465b1be38eda920f890125bdc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('name == \"Elston\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
