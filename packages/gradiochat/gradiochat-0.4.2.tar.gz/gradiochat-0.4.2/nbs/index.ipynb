{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jelle/code/gradiochat/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "from gradiochat.config import *\n",
    "from gradiochat import gradio_themes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gradiochat\n",
    "\n",
    "> App to easily create different Gradiochat apps with different context, system messages and gradio themes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "\n",
    "- Easy-to-use interface\n",
    "- Supports integration with various AI models\n",
    "- Real-time chat capabilities\n",
    "- Open-source and customizable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation can be found hosted on this GitHub [repository][repo]'s [pages][docs]. Additionally you can find package manager specific guidelines on [pypi][pypi] respectively.\n",
    "\n",
    "[repo]: https://github.com/Hopsakee/gradiochat\n",
    "[docs]: https://Hopsakee.github.io/gradiochat/\n",
    "[pypi]: https://pypi.org/project/gradiochat/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This comprehensive guide explains how to use the GradioChat package to create customizable LLM-powered chat applications with Gradio. GradioChat provides a simple yet powerful framework for building chat interfaces that can connect to various language models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the package using `pip` or `uv` using the explanation below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install latest from the GitHub [repository][repo]:\n",
    "\n",
    "```sh\n",
    "$ pip install git+https://github.com/Hopsakee/gradiochat.git\n",
    "```\n",
    "\n",
    "or from [pypi][pypi]\n",
    "\n",
    "```sh\n",
    "$ pip install gradiochat\n",
    "```\n",
    "\n",
    "\n",
    "[repo]: https://github.com/Hopsakee/gradiochat\n",
    "[docs]: https://Hopsakee.github.io/gradiochat/\n",
    "[pypi]: https://pypi.org/project/gradiochat/\n",
    "[conda]: https://anaconda.org/Hopsakee/gradiochat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick start\n",
    "\n",
    "Here's a minimal example to get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Create and launch the chat application\u001b[39;00m\n\u001b[1;32m     23\u001b[0m app \u001b[38;5;241m=\u001b[39m create_chat_app(config)\n\u001b[0;32m---> 24\u001b[0m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_interface\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlaunch()\n",
      "File \u001b[0;32m~/code/gradiochat/src/gradiochat/ui.py:71\u001b[0m, in \u001b[0;36mbuild_interface\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Build and return the Gradio interface\"\"\"\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m gr\u001b[38;5;241m.\u001b[39mBlocks(theme\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapp\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtheme, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapp\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mapp_name) \u001b[38;5;28;01mas\u001b[39;00m interface:\n\u001b[0;32m---> 71\u001b[0m     \u001b[43mc\u001b[49m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m gr\u001b[38;5;241m.\u001b[39mRow():\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;66;03m# Left column for logo\u001b[39;00m\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m gr\u001b[38;5;241m.\u001b[39mColumn(scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'c' is not defined"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "# Eval is false to prevent testing when nbdev_test or nbdev_prepare is run. The api_key is stored in a .env file and that is not accessible at test time.\n",
    "from gradiochat.config import ModelConfig, ChatAppConfig\n",
    "from gradiochat.ui import create_chat_app\n",
    "from pathlib import Path\n",
    "\n",
    "# Create model configuration\n",
    "model_config = ModelConfig(\n",
    "    model_name=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    provider=\"huggingface\",\n",
    "    api_key_env_var=\"HF_API_KEY\"  # Optional: Set in .env file or environment\n",
    ")\n",
    "\n",
    "# Create chat application configuration\n",
    "config = ChatAppConfig(\n",
    "    app_name=\"My Chat App\",\n",
    "    description=\"A simple chat application powered by Mistral\",\n",
    "    system_prompt=\"You are a helpful assistant.\",\n",
    "    model=model_config\n",
    ")\n",
    "\n",
    "# Create and launch the chat application\n",
    "app = create_chat_app(config)\n",
    "app.build_interface().launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "\n",
    "The core of GradioChat is its configuration system which uses Pydantic for validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ModelConfig\n",
    "\n",
    "The `ModelConfig` class defines how to connect to a language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradiochat.config import ModelConfig\n",
    "\n",
    "# HuggingFace model\n",
    "hf_model = ModelConfig(\n",
    "    model_name=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    provider=\"huggingface\",\n",
    "    api_key_env_var=\"HF_API_KEY\",  # Will read from environment variable\n",
    "    api_base_url=None,  # Optional: Custom API endpoint\n",
    "    max_completion_tokens=1024,\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message\n",
    "\n",
    "The Message class represents a single message in a conversation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradiochat.config import Message\n",
    "\n",
    "# Create a system message\n",
    "system_msg = Message(\n",
    "    role=\"system\",\n",
    "    content=\"You are a helpful assistant.\"\n",
    ")\n",
    "\n",
    "# Create a user message\n",
    "user_msg = Message(\n",
    "    role=\"user\",\n",
    "    content=\"Hello, can you help me with Python?\"\n",
    ")\n",
    "\n",
    "# Create an assistant message\n",
    "assistant_msg = Message(\n",
    "    role=\"assistant\",\n",
    "    content=\"Of course! I'd be happy to help with Python. What would you like to know?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatAppConfig\n",
    "\n",
    "The `ChatAppConfig` class is the main configuration for your chat application:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradiochat.config import ChatAppConfig, ModelConfig\n",
    "from pathlib import Path\n",
    "\n",
    "# Create model configuration\n",
    "model_config = ModelConfig(\n",
    "    model_name=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    provider=\"huggingface\",\n",
    "    api_key_env_var=\"HF_API_KEY\"\n",
    ")\n",
    "\n",
    "# Create chat application configuration\n",
    "config = ChatAppConfig(\n",
    "    app_name=\"Python Helper\",\n",
    "    description=\"Get help with Python programming\",\n",
    "    system_prompt=\"You are a Python expert who helps users with programming questions.\",\n",
    "    starter_prompt=\"Hello! I'm your Python assistant. Ask me any Python-related question.\",\n",
    "    context_files=[Path(\"docs/python_tips.md\")],  # Optional: Add context from files\n",
    "    model=model_config,\n",
    "    theme=None,  # Optional: Custom Gradio theme\n",
    "    logo_path=Path(\"assets/logo.png\"),  # Optional: Path to logo image\n",
    "    show_system_prompt=True,  # Whether to show system prompt in UI\n",
    "    show_context=True  # Whether to show context in UI\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Chat Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Environment Variables\n",
    "\n",
    "For API keys, it's recommended to use environment variables. You can create a ' `.env` file in your project root:\n",
    "\n",
    "`HF_API_KEY=your_huggingface_api_key_here`\n",
    "\n",
    "Then load it in your application:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "# Now create your ModelConfig with api_key_env_var\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Context Files\n",
    "\n",
    "You can provide additional context to your LLM by adding markdown files:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from pathlib import Path\n",
    "\n",
    "config = ChatAppConfig(\n",
    "    # ... other parameters\n",
    "    context_files=[\n",
    "        Path(\"docs/product_info.md\"),\n",
    "        Path(\"docs/faq.md\")\n",
    "    ],\n",
    "    # ... other parameters\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customization\n",
    "\n",
    "### Custom Themes\n",
    "\n",
    "You can customize the appearance of your chat application using [Gradio themes](https://www.gradio.app/guides/theming-guide). You can build those yourself with help from the `gradio_themebuilder` or you can use one of the predefined themes in `gradio_themes`. The predifined themes are listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- themeWDODelta\n"
     ]
    }
   ],
   "source": [
    "#| echo: false\n",
    "for t in gradio_themes.__all__:\n",
    "    print(f\"- {t}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import gradio as gr\n",
    "\n",
    "my_theme = gr.themes.Base(\n",
    "    primary_hue=\"fuchsia\",\n",
    ")\n",
    "\n",
    "# Use the theme in your config\n",
    "config = ChatAppConfig(\n",
    "    # ... other parameters\n",
    "    theme=my_theme,\n",
    "    # ... other parameters\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Reference\n",
    "\n",
    "### BaseChatApp\n",
    "\n",
    "The BaseChatApp class provides the core functionality for chat applications:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from gradiochat.app import BaseChatApp\n",
    "from gradiochat.config import ChatAppConfig\n",
    "\n",
    "# Create configuration\n",
    "config = ChatAppConfig(...)\n",
    "\n",
    "# Create base app\n",
    "base_app = BaseChatApp(config)\n",
    "\n",
    "# Generate a response\n",
    "response = base_app.generate_response(\"What is Python?\")\n",
    "\n",
    "# Generate a streaming response\n",
    "# IMPORTANT: I don't actually think this already works. To be continued.\n",
    "for chunk in base_app.generate_stream(\"Tell me about Python\"):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradioChat\n",
    "\n",
    "The `GradioChat` class provides the Gradio UI for the chat application:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from gradiochat.ui import GradioChat\n",
    "from gradiochat.app import BaseChatApp\n",
    "\n",
    "# Create base app\n",
    "base_app = BaseChatApp(config)\n",
    "\n",
    "# Create Gradio interface\n",
    "gradio_app = GradioChat(base_app)\n",
    "\n",
    "# Build and launch the interface\n",
    "interface = gradio_app.build_interface()\n",
    "interface.launch()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Clients\n",
    "\n",
    "The package currently supports HuggingFace models through the `HuggingFaceClient` class:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from gradiochat.app import HuggingFaceClient\n",
    "from gradiochat.config import ModelConfig, Message\n",
    "\n",
    "# Create model config\n",
    "model_config = ModelConfig(\n",
    "    model_name=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    provider=\"huggingface\",\n",
    "    api_key_env_var=\"HF_API_KEY\"\n",
    ")\n",
    "\n",
    "# Create client\n",
    "client = HuggingFaceClient(model_config)\n",
    "\n",
    "# Generate a completion\n",
    "messages = [\n",
    "    Message(role=\"system\", content=\"You are a helpful assistant.\"),\n",
    "    Message(role=\"user\", content=\"What is Python?\")\n",
    "]\n",
    "response = client.chat_completion(messages)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Example\n",
    "\n",
    "Here's a complete example that demonstrates most features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jelle/code/gradiochat/src/gradiochat/ui.py:89: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* Running on public URL: https://f1f738822af7fb3232.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://f1f738822af7fb3232.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| output: false\n",
    "import gradio as gr\n",
    "from gradiochat.config import ModelConfig, ChatAppConfig\n",
    "from gradiochat.gradio_themes import themeWDODelta\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Create a custom theme\n",
    "theme = themeWDODelta\n",
    "\n",
    "# Create model configuration\n",
    "model_config = ModelConfig(\n",
    "    model_name=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    provider=\"huggingface\",\n",
    "    api_key_env_var=\"HF_API_KEY\",\n",
    "    max_completion_tokens=2048,\n",
    "    temperature=0.8\n",
    ")\n",
    "\n",
    "# Create chat application configuration\n",
    "config = ChatAppConfig(\n",
    "    app_name=\"Python Expert\",\n",
    "    description=\"Get expert help with Python programming\",\n",
    "    system_prompt=\"You are a Python expert who helps users with programming questions. Provide clear, concise, and accurate information.\",\n",
    "    starter_prompt=\"Hello! I'm your Python assistant. How can I help you today?\",\n",
    "    context_files=[Path(\"docs/python_reference.md\")],\n",
    "    model=model_config,\n",
    "    theme=theme,\n",
    "    logo_path=Path(\"assets/python_logo.png\"),\n",
    "    show_system_prompt=True,\n",
    "    show_context=True\n",
    ")\n",
    "\n",
    "# Create and launch the chat application\n",
    "from gradiochat.ui import create_chat_app\n",
    "app = create_chat_app(config)\n",
    "app.build_interface().launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To close all existing clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.close_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developer Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I built this using `nbdev` [notebook development tutorial](https://nbdev.fast.ai/getting_started.html) from the company [fast.ai](https://www.fast.ai).\n",
    "\n",
    "I also used the `uv` [python package and environment manager](https://docs.astral.sh/uv/).\n",
    "\n",
    "Officially `nbdev` doesn't support `uv`. It works with `conda` or `pip`, preferably with a single environment for all your Python projects if I understand correctly. The `nbdev` package then handles the dependencies and such via the `setings.ini` and `setup.py` and `requirements.txt`. But don't take my word for that, dive into the actual documentation.\n",
    "\n",
    "I stumbled into some quircks trying to combine `nbdev` and `uv`. Most of those are probably a result from `nbdev` needing `settings.ini` and/or `settings.py`, while `uv` uses `pyproject.toml`.\n",
    "All of this, is to say. You might possibly run into some issues running this package because I wanted to do something that's not officially supported or possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While developing I learned a few things that seemed to work after some struggles.\n",
    "\n",
    "1. Make sure to use Python 3.10 if you want to use Gradio. This is strange. With `uv` I can use 3.11 and Gradio just fine. But the moment I push to Github the `nbdev` CI action fails with the statement that my app can at most support 3.10.16. I think that is because in Github `pip` is used and not `uv`.\n",
    "2. I also think you need Python 3.10 if you want to deploy to HuggingSpaces. Lower is possible, higher is not yet supported by HuggingSpaces.\n",
    "3. I thought that we needed Python 3.11 to be able to combine `nbdev` with `uv`. But I haven't noticed any issues yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install gradiochat in Development mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "# make sure gradiochat package is installed in development mode\n",
    "$ pip install -e .\n",
    "\n",
    "# make changes under nbs/ directory\n",
    "# ...\n",
    "\n",
    "# compile to have changes apply to gradiochat\n",
    "$ nbdev_prepare\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
