{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Interface\n",
    "\n",
    "> Gradio interface for the chat application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jelle/code/gradiochat/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "#| hide\n",
    "import gradio as gr\n",
    "import tempfile\n",
    "import datetime\n",
    "import os\n",
    "from typing import List, Tuple, Dict, Generator\n",
    "from fastcore.basics import patch\n",
    "from gradiochat.config import ChatAppConfig, ModelConfig\n",
    "from gradiochat.app import BaseChatApp\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the class for the User interface\n",
    "\n",
    "A class that creates and manages a Gradio-based chat interface.\n",
    "\n",
    "This class provides a web-based user interface for interacting with chat models.\n",
    "It handles the display of messages, streaming of responses, and various UI elements\n",
    "like buttons for sending messages, clearing chat history, and exporting conversations.\n",
    "\n",
    "Attributes:\n",
    "\n",
    "- app (BaseChatApp): The underlying chat application that handles message processing. It accepts an instance of the class `BaseChatApp` which is defined in the module `app.py`.\n",
    "- interface (gr.Blocks, optional): The Gradio interface object once built.\n",
    "\n",
    "The interface is built within this class with the `build_interface` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import statement\n",
    "\n",
    "```python\n",
    "from gradiochat.ui import *\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GradioChat:\n",
    "    \"\"\"Gradio interface for the chat application\"\"\"\n",
    "    \n",
    "    def __init__(self, app: BaseChatApp):\n",
    "        \"\"\"Initialize with a configured BaseChatApp\"\"\"\n",
    "        self.app = app\n",
    "        self.interface = None\n",
    "    \n",
    "    def respond(self, message: str, chat_history: List[Dict[str, str]]) -> Tuple[str, List[Tuple[str, str]]]:\n",
    "        \"\"\"Generate a response to the user message and update chat history\"\"\"\n",
    "        # Store the current chat history in the app\n",
    "        self.app.chat_history = chat_history\n",
    "        \n",
    "        # Generate response\n",
    "        response = self.app.generate_response(message)\n",
    "        \n",
    "        # Update chat history\n",
    "        chat_history.append({\"role\": \"user\", \"content\": message})\n",
    "        chat_history.append({\"role\": \"assistant\", \"content\": response})\n",
    "        \n",
    "        # Return empty message (to clear input) and updated history\n",
    "        return \"\", chat_history\n",
    "    \n",
    "    def respond_stream(self, message: str, chat_history: List[Tuple[str, str]]) -> Generator[Tuple[str, List[Tuple[str, str]]], None, None]:\n",
    "        \"\"\"Generate a streaming response to the user message\"\"\"\n",
    "        # Store the current chat history in the app\n",
    "        self.app.chat_history = chat_history\n",
    "        \n",
    "        # Add user message to history with empty assistant response\n",
    "        chat_history.append({\"role\": \"user\", \"content\": message})\n",
    "        \n",
    "        # Stream the response\n",
    "        accumulated_text = \"\"\n",
    "        for text_chunk in self.app.generate_stream(message):\n",
    "            accumulated_text += text_chunk\n",
    "            \n",
    "            # Update the last assistant message\n",
    "            updated_history = chat_history.copy()\n",
    "            updated_history.append({\"role\": \"assistant\", \"content\": accumulated_text})\n",
    "            \n",
    "            # Yield empty message and updated history\n",
    "            yield \"\", updated_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the interface for the GradioChat class\n",
    "\n",
    "Build and return the Gradio interface.\n",
    "\n",
    "This method constructs the complete Gradio UI with all components including:\n",
    "- App title and logo\n",
    "- Chat display area\n",
    "- Message input field\n",
    "- Control buttons (Send, Clear)\n",
    "- Export functionality\n",
    "- System information display\n",
    "\n",
    "The interface is configured according to the settings in the app's config.\n",
    "\n",
    "Returns:\n",
    "    gr.Blocks: The constructed Gradio interface object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Learned: `@patch`**\n",
    "> \n",
    "> This is a decorator used in `nbdev` to make it possible to spread the methods and properties of a class over multiple notebook cells. By using `@patch` and setting `self:<classname>` the `nbdev` style written code 'knows' to which class the method or property belongs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "@patch\n",
    "def build_interface(self:GradioChat) -> gr.Blocks:\n",
    "    \"\"\"Build and return the Gradio interface\"\"\"\n",
    "    with gr.Blocks(theme=self.app.config.theme, title=self.app.config.app_name) as interface:\n",
    "        with gr.Row():\n",
    "            # Left column for logo\n",
    "            with gr.Column(scale=1):\n",
    "                if self.app.config.logo_path:\n",
    "                    gr.Image(value=self.app.config.logo_path,\n",
    "                        show_label=False,\n",
    "                        container=False,\n",
    "                        show_download_button=False,\n",
    "                        show_fullscreen_button=False,\n",
    "                        height=80,\n",
    "                        width=80)\n",
    "                else:\n",
    "                    gr.Image(value=None,\n",
    "                        show_label=False,\n",
    "                        container=False,\n",
    "                        show_download_button=False,\n",
    "                        show_fullscreen_button=False,\n",
    "                        height=80,\n",
    "                        width=80)\n",
    "            with gr.Column(scale=4):\n",
    "                # App title and description\n",
    "                gr.Markdown(f\"# {self.app.config.app_name}\")\n",
    "                if self.app.config.description:\n",
    "                    gr.Markdown(self.app.config.description)\n",
    "        \n",
    "        # Chat interface\n",
    "        chatbot = gr.Chatbot(\n",
    "            height=500,\n",
    "            label=\"Conversation\",\n",
    "            type=\"messages\",\n",
    "            editable=True,\n",
    "            show_copy_button=True,\n",
    "            show_copy_all_button=True)\n",
    "        msg = gr.Textbox(\n",
    "            placeholder=\"Type your message here...\",\n",
    "            label=\"Your message\",\n",
    "            lines=2\n",
    "        )\n",
    "        \n",
    "        # Buttons\n",
    "        with gr.Row():\n",
    "            submit_btn = gr.Button(\"Send\", variant=\"primary\")\n",
    "            clear_btn = gr.ClearButton([msg, chatbot], value=\"Clear chat\")\n",
    "\n",
    "        # Export functionality\n",
    "        with gr.Accordion(\"Export Options\", open=False):\n",
    "            gr.Markdown(\"Select export options:\")\n",
    "            \n",
    "            # Buttons for copying and downloading\n",
    "            with gr.Row():\n",
    "                download_btn = gr.DownloadButton(\n",
    "                    label=\"Download as Markdown\",\n",
    "                    variant=\"secondary\",\n",
    "                    visible=True,\n",
    "                    interactive=True\n",
    "                )\n",
    "        \n",
    "        # System prompt and context viewer (collapsible)\n",
    "        with gr.Accordion(\"View System Information\", open=False):\n",
    "            if self.app.config.show_system_prompt:\n",
    "                gr.Markdown(f\"### System Prompt\\n{self.app.config.system_prompt}\")\n",
    "            \n",
    "            if self.app.config.show_context and hasattr(self.app, 'context_text') and self.app.context_text:\n",
    "                gr.Markdown(f\"### Additional Context\\n{self.app.context_text}\")\n",
    "        \n",
    "        # Set up event handlers\n",
    "        submit_btn.click(\n",
    "            self.respond,\n",
    "            inputs=[msg, chatbot],\n",
    "            outputs=[msg, chatbot]\n",
    "        )\n",
    "        \n",
    "        msg.submit(\n",
    "            self.respond,\n",
    "            inputs=[msg, chatbot],\n",
    "            outputs=[msg, chatbot]\n",
    "        )\n",
    "\n",
    "            # Export event handlers\n",
    "        def format_last_response(chat_history):\n",
    "            if not chat_history:\n",
    "                return \"No conversation to export.\"\n",
    "            msg = chat_history[-1]\n",
    "\n",
    "            return f\"# Response\\n\\n{msg['content']}\"\n",
    "        \n",
    "        def format_full_conversation(chat_history):\n",
    "            if not chat_history:\n",
    "                return \"No conversation to export.\"\n",
    "            \n",
    "            md_str = f\"# {self.app.config.app_name} - Conversation\\n\\n\"\n",
    "            \n",
    "            for msg in chat_history:\n",
    "                role = msg[\"role\"]\n",
    "                content = msg[\"content\"]\n",
    "                if role == \"user\":\n",
    "                    md_str += f\"**👤 User:**\\n{content}\\n\\n\"\n",
    "                elif role == \"assistant\":\n",
    "                    md_str += f\"**🤖 Assistant+**\\n{content}\\n\\n\"\n",
    "                else:\n",
    "                    md_str += f\"**{role}:**\\n{content}\\n\\n\"\n",
    "            return md_str\n",
    "            \n",
    "        # File download functionality\n",
    "        def download_chat(chat_history):\n",
    "            md_content = format_full_conversation(chat_history)\n",
    "            temp_dir = tempfile.gettempdir()\n",
    "            filename = f\"conversation_{datetime.today().strftime('%Y-%m-%d')}.md\"\n",
    "            filepath = Path(temp_dir) / filename\n",
    "            \n",
    "            with open(filepath, 'w', encoding='utf-8') as f:\n",
    "                f.write(md_content)\n",
    "            \n",
    "            os.chmod(filepath, 0o644)\n",
    "\n",
    "            return filepath\n",
    "\n",
    "        download_btn.click(\n",
    "            fn=download_chat,\n",
    "            inputs=[chatbot],\n",
    "            outputs=[download_btn]\n",
    "        )\n",
    "            \n",
    "        # Initialize with starter prompt if available\n",
    "        if self.app.config.starter_prompt:\n",
    "            chatbot.value = [{\"role\": \"assistant\", \"content\": self.app.config.starter_prompt}]\n",
    "        \n",
    "        self.interface = interface\n",
    "        return interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method to launch the app that is instantiated from the class `GradioChat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def launch(self:GradioChat, **kwargs):\n",
    "    \"\"\"Launch the Gradio interface\"\"\"\n",
    "    if self.interface is None:\n",
    "        self.build_interface()\n",
    "    \n",
    "    return self.interface.launch(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create chat app from the class `GradioChat`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch the Gradio interface.\n",
    "\n",
    "This method builds the interface if it hasn't been built yet and then launches the Gradio web server to make the interface accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_chat_app(\n",
    "        config: ChatAppConfig # Instance from the config.ChatAppConfig module\n",
    "        ) -> GradioChat:\n",
    "    \"\"\"Create a complete chat application from a configuration\"\"\"\n",
    "    base_app = BaseChatApp(config)\n",
    "    return GradioChat(base_app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Below is an example to create a simple chat UI wich follows more or less the styling confentions from Waterschap Drents Overijsselse Delta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The environment variable TG_API_KEY is not found in the .env file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 40\u001b[0m\n\u001b[1;32m     25\u001b[0m test_config \u001b[38;5;241m=\u001b[39m ChatAppConfig(\n\u001b[1;32m     26\u001b[0m     app_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJob Description Assistant\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     27\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChat with an AI to create better job descriptions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     logo_path\u001b[38;5;241m=\u001b[39mPath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/wdod_logo.svg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Create and launch the app\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m app \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_chat_app\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m app\u001b[38;5;241m.\u001b[39mlaunch(share\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;66;03m# Set share=False if you don't want a public URL\u001b[39;00m\n\u001b[1;32m     42\u001b[0m         pwa\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;66;03m# Set pwa=False if you don't want a progressive web app.\u001b[39;00m\n\u001b[1;32m     43\u001b[0m         )\n",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m, in \u001b[0;36mcreate_chat_app\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_chat_app\u001b[39m(\n\u001b[1;32m      3\u001b[0m         config: ChatAppConfig \u001b[38;5;66;03m# Instance from the config.ChatAppConfig module\u001b[39;00m\n\u001b[1;32m      4\u001b[0m         ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m GradioChat:\n\u001b[1;32m      5\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a complete chat application from a configuration\"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     base_app \u001b[38;5;241m=\u001b[39m \u001b[43mBaseChatApp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m GradioChat(base_app)\n",
      "File \u001b[0;32m~/code/gradiochat/src/gradiochat/app.py:236\u001b[0m, in \u001b[0;36mBaseChatApp.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat_history \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_context()\n\u001b[0;32m--> 236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_llm_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/gradiochat/src/gradiochat/app.py:221\u001b[0m, in \u001b[0;36mcreate_llm_client\u001b[0;34m(model_config)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m HuggingFaceClient(model_config)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_config\u001b[38;5;241m.\u001b[39mprovider\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtogetherai\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTogetherAiClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_config\u001b[38;5;241m.\u001b[39mprovider\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mollama\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m OllamaClient(model_config)\n",
      "File \u001b[0;32m~/code/gradiochat/src/gradiochat/app.py:81\u001b[0m, in \u001b[0;36mTogetherAiClient.__init__\u001b[0;34m(self, model_config)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initialize the client with model configuration\"\"\"\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config \u001b[38;5;241m=\u001b[39m model_config\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m OpenAI(\n\u001b[1;32m     80\u001b[0m     base_url\u001b[38;5;241m=\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39mapi_base_url \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api.together.xyz/v1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m# Default to Together AI Inference API if no base URL is provided\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m     api_key\u001b[38;5;241m=\u001b[39m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_key\u001b[49m,\n\u001b[1;32m     82\u001b[0m )\n",
      "File \u001b[0;32m~/code/gradiochat/src/gradiochat/config.py:38\u001b[0m, in \u001b[0;36mModelConfig.api_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key_env_var):\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key_env_var)\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe environment variable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key_env_var\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not found in the .env file.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: The environment variable TG_API_KEY is not found in the .env file."
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "# Eval is false to prevent testing when nbdev_test or nbdev_prepare is run. The api_key is stored in a .env file and that is not accessible at test time.\n",
    "themeWDODelta = gr.themes.Base(\n",
    "    primary_hue=gr.themes.Color(c100=\"#ffedd5\", c200=\"#ffddb3\", c300=\"#fdba74\", c400=\"#f29100\", c50=\"#fff7ed\", c500=\"#f97316\", c600=\"#ea580c\", c700=\"#c2410c\", c800=\"#9a3412\", c900=\"#7c2d12\", c950=\"#6c2e12\"),\n",
    "    neutral_hue=\"slate\",\n",
    "    radius_size=\"sm\",\n",
    "    font=['VivalaSansRound', 'ui-sans-serif', 'system-ui', 'sans-serif'],\n",
    ").set(\n",
    "    embed_radius='*radius_xs',\n",
    "    border_color_accent='*primary_400',\n",
    "    border_color_accent_dark='*secondary_700',\n",
    "    border_color_primary='*secondary_700',\n",
    "    border_color_primary_dark='*secondary_700',\n",
    "    color_accent='*primary_400',\n",
    "    shadow_drop='*shadow_drop_lg',\n",
    "    button_primary_background_fill='*primary_400',\n",
    "    button_primary_background_fill_dark='*primary_400',\n",
    "    button_primary_background_fill_hover='*secondary_700',\n",
    "    button_primary_background_fill_hover_dark='*secondary_700',\n",
    "    button_primary_border_color='*secondary_700',\n",
    "    button_primary_border_color_dark='*secondary_700'\n",
    ")\n",
    "\n",
    "# Create a test configuration\n",
    "test_config = ChatAppConfig(\n",
    "    app_name=\"Job Description Assistant\",\n",
    "    description=\"Chat with an AI to create better job descriptions\",\n",
    "    system_prompt=\"You are an assistant that helps users create professional job descriptions. Ask questions to gather information about the position and responsibilities.\",\n",
    "    starter_prompt=\"Hello! I'm your job description assistant. Tell me about the position you'd like to create a description for.\",\n",
    "    model=ModelConfig(\n",
    "        provider=\"togetherai\",\n",
    "        model_name=\"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "        api_key_env_var=\"TG_API_KEY\"\n",
    "    ),\n",
    "    theme=themeWDODelta,\n",
    "    logo_path=Path(\"../data/wdod_logo.svg\")\n",
    ")\n",
    "\n",
    "# Create and launch the app\n",
    "app = create_chat_app(test_config)\n",
    "app.launch(share=False, # Set share=False if you don't want a public URL\n",
    "        pwa=True # Set pwa=False if you don't want a progressive web app.\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close all Gradio clients and ports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gr.close_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
