{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Client Example\n",
    "\n",
    "This notebook demonstrates how to use the combined `LangGateLocal` client, which provides access to both registry and parameter transformation functionality in a single client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint as pp\n",
    "\n",
    "# Optional environment variables\n",
    "# os.environ[\"LANGGATE_CONFIG\"] = \"path/to/langgate_config.yaml\"\n",
    "# os.environ[\"LANGGATE_MODELS\"] = \"path/to/langgate_models.json\"\n",
    "# os.environ[\"LOG_LEVEL\"] = \"debug\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Combined Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgate.sdk import LangGateLocal\n",
    "\n",
    "# Initialize the combined client\n",
    "# LangGateLocal is a singleton that combines both registry and transformer functionality\n",
    "client = LangGateLocal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Available Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-04-05 21:03:16\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mrefreshed_model_cache         \u001b[0m \u001b[36mmodel_count\u001b[0m=\u001b[35m5\u001b[0m\n",
      "Available models: 5\n",
      "- openai/gpt-4o: GPT-4o\n",
      "- openai/o1: o1\n",
      "- openai/o1-high: o1-high\n",
      "- anthropic/claude-3-7-sonnet: Claude-3.7 Sonnet\n",
      "- anthropic/claude-3-7-sonnet-reasoning: Claude-3.7 Sonnet R\n"
     ]
    }
   ],
   "source": [
    "# List available models\n",
    "models = await client.list_models()\n",
    "print(f\"Available models: {len(models)}\")\n",
    "for model in models[:5]:\n",
    "    print(f\"- {model.id}: {model.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample user parameters\n",
    "input_params = {\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_tokens\": 1000,\n",
    "    \"stream\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Model Info and Transform Parameters\n",
    "\n",
    "Using the combined client, we can get model information and transform parameters from a unified interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: GPT-4o\n",
      "Provider: OpenAI\n",
      "Description: The GPT-4o (omni) model from OpenAI builds upon the GPT-4 series with improved performance and multimodal capabilities. GPT-4o is great for most tasks.\n",
      "\n",
      "Transformed parameters:\n",
      "{'api_key': SecretStr('**********'),\n",
      " 'base_url': 'https://api.openai.com/v1',\n",
      " 'max_tokens': 1000,\n",
      " 'model': 'gpt-4o',\n",
      " 'stream': True,\n",
      " 'temperature': 0.7}\n"
     ]
    }
   ],
   "source": [
    "if models:\n",
    "    model_id = models[0].id\n",
    "\n",
    "    # Get model info\n",
    "    model_info = await client.get_model_info(model_id)\n",
    "    print(f\"Model: {model_info.name}\")\n",
    "    print(f\"Provider: {model_info.provider.name}\")\n",
    "    print(f\"Description: {model_info.description}\")\n",
    "\n",
    "    # Transform parameters\n",
    "    transformed = await client.get_params(model_id, input_params)\n",
    "    print(\"\\nTransformed parameters:\")\n",
    "    pp(transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Model-Specific Configurations\n",
    "\n",
    "Different models may have different parameter transformations defined in `langgate_config.yaml`.\n",
    "You can define \"virtual models\" with IDs referring to a model + a configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Claude-3.7 Sonnet R\n",
      "Provider: Anthropic\n",
      "Description: Claude-3.7 Sonnet with reasoning capabilities.\n",
      "\n",
      "Transformed parameters:\n",
      "{'api_key': SecretStr('**********'),\n",
      " 'base_url': 'https://api.anthropic.com',\n",
      " 'max_tokens': 1000,\n",
      " 'model': 'claude-3-7-sonnet-20250219',\n",
      " 'stream': True,\n",
      " 'thinking': {'budget_tokens': 1024, 'type': 'enabled'}}\n"
     ]
    }
   ],
   "source": [
    "# Using a model with a specific configuration.\n",
    "# Anthropic has no actual model with this ID. We define it ourselves,\n",
    "# to reference claude-3-7-sonnet with a specific reasoning configuration.\n",
    "model_id = \"anthropic/claude-3-7-sonnet-reasoning\"\n",
    "\n",
    "# Get model info\n",
    "model_info = await client.get_model_info(model_id)\n",
    "print(f\"Model: {model_info.name}\")\n",
    "print(f\"Provider: {model_info.provider.name}\")\n",
    "print(f\"Description: {model_info.description}\")\n",
    "\n",
    "# Transform parameters\n",
    "transformed = await client.get_params(model_id, input_params)\n",
    "print(\"\\nTransformed parameters:\")\n",
    "pp(transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Model Capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capabilities for GPT-4o:\n",
      "{'supports_parallel_tool_calls': True,\n",
      " 'supports_prompt_caching': True,\n",
      " 'supports_response_schema': True,\n",
      " 'supports_system_messages': True,\n",
      " 'supports_tool_choice': True,\n",
      " 'supports_tools': True,\n",
      " 'supports_vision': True}\n",
      "\n",
      "Transformed parameters with tools:\n",
      "{'api_key': SecretStr('**********'),\n",
      " 'base_url': 'https://api.openai.com/v1',\n",
      " 'max_tokens': 1000,\n",
      " 'model': 'gpt-4o',\n",
      " 'stream': True,\n",
      " 'temperature': 0.7,\n",
      " 'tools': [{'function': {'description': 'Get the current weather in a location',\n",
      "                         'name': 'get_weather',\n",
      "                         'parameters': {'properties': {'location': {'description': 'The '\n",
      "                                                                                   'city '\n",
      "                                                                                   'and '\n",
      "                                                                                   'country, '\n",
      "                                                                                   'e.g., '\n",
      "                                                                                   'Cork, '\n",
      "                                                                                   'Ireland',\n",
      "                                                                    'type': 'string'}},\n",
      "                                        'required': ['location'],\n",
      "                                        'type': 'object'}},\n",
      "            'type': 'function'}]}\n"
     ]
    }
   ],
   "source": [
    "# Check model capabilities\n",
    "if models:\n",
    "    model_id = models[0].id\n",
    "    model_info = await client.get_model_info(model_id)\n",
    "\n",
    "    print(f\"Capabilities for {model_info.name}:\")\n",
    "    pp(model_info.capabilities.model_dump(exclude_none=True))\n",
    "\n",
    "    # Adjust parameters based on capabilities\n",
    "    custom_params = input_params.copy()\n",
    "\n",
    "    # Example: Add tools if supported\n",
    "    if model_info.capabilities.supports_tools:\n",
    "        custom_params[\"tools\"] = [\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"get_weather\",\n",
    "                    \"description\": \"Get the current weather in a location\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"location\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The city and country, e.g., Cork, Ireland\",\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"location\"],\n",
    "                    },\n",
    "                },\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    # Transform the custom parameters\n",
    "    transformed = await client.get_params(model_id, custom_params)\n",
    "    print(\"\\nTransformed parameters with tools:\")\n",
    "    pp(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
