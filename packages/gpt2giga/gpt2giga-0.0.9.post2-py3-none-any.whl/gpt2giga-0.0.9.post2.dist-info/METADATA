Metadata-Version: 2.1
Name: gpt2giga
Version: 0.0.9.post2
Summary: 
License: MIT
Author: Konstantin Krestnikov
Author-email: rai220@gmail.com
Requires-Python: >=3.9,<4.0
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Requires-Dist: aiohttp (>=3.10.10,<4.0.0)
Requires-Dist: asyncio (>=3.4.3,<4.0.0)
Requires-Dist: gigachat (>=0.1.39post1,<0.2.0)
Requires-Dist: python-dotenv (>=1.0.1,<2.0.0)
Requires-Dist: tiktoken (>=0.9.0,<0.10.0)
Description-Content-Type: text/markdown

# Прокси для использования GigaChat вместо OpenAI GPT

Данный проект представляет собой HTTP-прокси, который позволяет подменять использование ChatGPT на GigaChat в тех случаях, когда возможна настройка URL для взаимодействия с ChatGPT. Утилита поддерживает все основные функции взаимодействия с чат-моделями, включая поддержку работы с функциями, стриминг-ответов и проксирование эндпоинтов для `embeddings`.

![alt text](image.png)

## Основные возможности

- **Полная замена**: утилита подменяет использование ChatGPT на GigaChat, позволяя использовать все его возможности.
- **Поддержка функций**: корректно обрабатываются вызовы функций через API, включая передачу и выполнение функций с аргументами.
- **Поддержка стриминга**: возможно получение ответа стримом (построчная отправка фрагментов) при запросах с параметром `stream=true`.
- **Проксирование Embeddings**: поддержка эндпоинтов `/embeddings` и `/v1/embeddings`.
- **Асинхронный HTTP-прокси**: поддерживает многопоточную обработку запросов для эффективной работы с большим количеством клиентов.
- **Простота настройки**: конфигурация через аргументы командной строки или переменные окружения (`.env`).
- **Поддержка логирования**: при включённом `verbose`-режиме отображаются подробные сведения о запросах и ответах.

## Установка

1. Установите пакет из pypi:
   ```bash
   pip install gpt2giga
   ```
   Или напрямую из исходников:
   ```bash
   pip install git+https://github.com/ai-forever/gpt2giga.git
   ```

2. Переименуйте файл `.env.example` в `.env` и расположите его в корне вашего проекта, укажите необходимые учетные данные для доступа к GigaChat:
   ```bash
   cp .env.example .env
   ```
   Обратите внимание, что поддерживаются различные способы авторизации в зависимости от типа вашей учетной записи.
   Также можно настроить другие переменные, поддерживаемые GigaChat (см. [документацию](https://github.com/ai-forever/gigachat)).

## Использование

После установки пакет добавит команду `gpt2giga`, с помощью которой вы можете запускать прокси-сервер.

### Пример простого запуска

```bash
gpt2giga
```
По умолчанию сервер запустится на `localhost:8090` (при отсутствии соответствующих переменных окружения).

### Аргументы командной строки

- `--host <HOST>` — хост, на котором будет запущен прокси (по умолчанию `localhost`).
- `--port <PORT>` — порт, на котором будет запущен прокси (по умолчанию `8090`).
- `--verbose` — включить подробный вывод логов (запросы и ответы).
- `--pass-model` — передавать в GigaChat модель, которую указал клиент в поле `model` в режиме чата.
- `--pass-token` — передавать токен, полученный в заголовке `Authorization`, в GigaChat. С помощью него можно настраивать передачу ключей в GigaChat через `OPENAI_API_KEY`
- `--base-url <BASE_URL>` — базовый URL для GigaChat API (по умолчанию берётся из переменной `GIGACHAT_BASE_URL` или значения `BASE_URL` внутри пакета).
- `--model <MODEL>` — модель по умолчанию для запросов в GigaChat (по умолчанию `GIGACHAT_MODEL`).
- `--timeout <TIMEOUT>` — таймаут для запросов к GigaChat (по умолчанию `600` секунд).
- `--embeddings <EMBED_MODEL>` — модель Embeddings (по умолчанию `EmbeddingsGigaR`).
- `--env-path <PATH>` — путь до .env-файла (по умолчанию ищется `.env` в текущей директории).

### Пример использования с кастомными настройками

```bash
gpt2giga \
    --host 127.0.0.1 \
    --port 8080 \
    --verbose \
    --pass-model \
    --pass-token \
    --base-url https://gigachat.devices.sberbank.ru/api/v1 \
    --model GigaChat-Max \
    --timeout 300 \
    --embeddings EmbeddingsGigaR
```

После запуска сервер будет слушать указанный хост и порт и перенаправлять все запросы, адресованные ChatGPT, на GigaChat.

## Пример интеграции

Любое приложение, которое взаимодействует с ChatGPT через настраиваемый URL (например, в настройках вы указываете `API_URL=https://api.openai.com/v1/`), можно «обмануть», подставив вместо `https://api.openai.com/v1/` адрес вашего запущенного прокси, например, `http://localhost:8090/v1/`. Тогда все запросы к ChatGPT будут перенаправлены в GigaChat.

То же самое справедливо для эндпоинтов `/embeddings` или `/v1/embeddings`, которые будет обслуживать прокси и отправлять запросы к GigaChat для генерации эмбеддингов.

## Переменные окружения

Вы можете либо передавать все параметры напрямую через аргументы, либо использовать `.env` / переменные окружения. Ниже список основных переменных, которые можно переопределить (название = значение по умолчанию):

- `PROXY_HOST="localhost"` — хост для запуска прокси.
- `PROXY_PORT="8090"` — порт для запуска прокси.
- `GPT2GIGA_VERBOSE="False"` — выводить ли подробную информацию (True/False).
- `GPT2GIGA_PASS_MODEL="False"` — передавать ли модель, указанную в запросе, непосредственно в GigaChat.
- `GPT2GIGA_PASS_TOKEN="False"` — пробрасывать ли токен авторизации дальше в GigaChat.
- `GIGACHAT_BASE_URL="https://gigachat.devices.sberbank.ru/api/v1"` — базовый URL GigaChat.
- `GIGACHAT_MODEL="GigaChat"` — модель GigaChat по умолчанию.
- `GPT2GIGA_TIMEOUT="600"` — таймаут для запросов (в секундах).
- `GPT2GIGA_EMBEDDINGS="EmbeddingsGigaR"` — модель для эндпоинта `/embeddings`.

Также при необходимости можно настроить:

- `GIGACHAT_USER` и `GIGACHAT_PASSWORD` — если требуется аутентификация по логину/паролю.
- `GIGACHAT_CREDENTIALS` — если нужно передавать токен в стиле `Bearer giga-cred-...`.
- `GIGACHAT_ACCESS_TOKEN` — если уже есть готовый токен аутентификации.

## Авторизация через заголовок

Если вы запускаете прокси с флагом `--pass-token` (или переменной окружения `GPT2GIGA_PASS_TOKEN=True`), то прокси будет пытаться преобразовать заголовок `Authorization` в формат, понятный GigaChat.  
Поддерживаются варианты:

- `giga-cred-<credentials>:<scope>`
- `giga-user-<user>:<password>`
- `giga-auth-<access_token>`

## Совместимые решения
Ниже приведен список проверенных приложений, работа с которыми возможна через gpt2giga.

### [Aider](https://aider.chat/)
Aider - AI-ассистент для написания приложений. Для запуска используйте следующую команду:
```
aider --openai-api-base http://localhost:8090 --model gpt-4o --openai-api-key 123
```

Более подробно про настройку aider с помощью gpt2giga можно прочитать [здесь](integrations/aider/README.md)

### [n8n](https://n8n.io/)
Платформа для создания nocode агентов

## Лицензия

Этот проект распространяется под лицензией MIT. См. [LICENSE](LICENSE) для получения подробной информации.

