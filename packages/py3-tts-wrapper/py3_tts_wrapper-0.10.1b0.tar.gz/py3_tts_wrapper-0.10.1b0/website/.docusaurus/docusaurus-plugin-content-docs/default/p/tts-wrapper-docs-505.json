{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"docs":[{"type":"category","label":"Getting Started","items":[{"type":"link","label":"Introduction","href":"/tts-wrapper/docs/intro","docId":"intro","unlisted":false},{"type":"link","label":"Installation","href":"/tts-wrapper/docs/installation","docId":"installation","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Guides","items":[{"type":"link","label":"Basic Usage","href":"/tts-wrapper/docs/guides/basic-usage","docId":"guides/basic-usage","unlisted":false},{"type":"link","label":"SSML Support","href":"/tts-wrapper/docs/guides/ssml","docId":"guides/ssml","unlisted":false},{"type":"link","label":"Audio Control","href":"/tts-wrapper/docs/guides/audio-control","docId":"guides/audio-control","unlisted":false},{"type":"link","label":"Streaming","href":"/tts-wrapper/docs/guides/streaming","docId":"guides/streaming","unlisted":false},{"type":"link","label":"Callbacks","href":"/tts-wrapper/docs/guides/callbacks","docId":"guides/callbacks","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Engines","items":[{"type":"link","label":"TTS Engines Overview","href":"/tts-wrapper/docs/engines/overview","docId":"engines/overview","unlisted":false},{"type":"link","label":"AWS Polly","href":"/tts-wrapper/docs/engines/aws-polly","docId":"engines/aws-polly","unlisted":false},{"type":"link","label":"Google Cloud TTS","href":"/tts-wrapper/docs/engines/google-cloud","docId":"engines/google-cloud","unlisted":false},{"type":"link","label":"Microsoft Azure TTS","href":"/tts-wrapper/docs/engines/microsoft-azure","docId":"engines/microsoft-azure","unlisted":false},{"type":"link","label":"IBM Watson TTS","href":"/tts-wrapper/docs/engines/ibm-watson","docId":"engines/ibm-watson","unlisted":false},{"type":"link","label":"ElevenLabs TTS","href":"/tts-wrapper/docs/engines/elevenlabs","docId":"engines/elevenlabs","unlisted":false},{"type":"link","label":"Play.HT TTS","href":"/tts-wrapper/docs/engines/playht","docId":"engines/playht","unlisted":false},{"type":"link","label":"Wit.ai TTS","href":"/tts-wrapper/docs/engines/witai","docId":"engines/witai","unlisted":false},{"type":"link","label":"espeak","href":"/tts-wrapper/docs/engines/espeak","docId":"engines/espeak","unlisted":false},{"type":"link","label":"SAPI TTS","href":"/tts-wrapper/docs/engines/sapi","docId":"engines/sapi","unlisted":false},{"type":"link","label":"AVSynth TTS","href":"/tts-wrapper/docs/engines/avsynth","docId":"engines/avsynth","unlisted":false},{"type":"link","label":"GoogleTrans TTS","href":"/tts-wrapper/docs/engines/googletrans","docId":"engines/googletrans","unlisted":false},{"type":"link","label":"Sherpa-ONNX TTS","href":"/tts-wrapper/docs/engines/sherpaonnx","docId":"engines/sherpaonnx","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Developer Guide","items":[{"type":"link","label":"Developer Overview","href":"/tts-wrapper/docs/developer/overview","docId":"developer/overview","unlisted":false},{"type":"link","label":"Adding New Engines","href":"/tts-wrapper/docs/developer/adding-engines","docId":"developer/adding-engines","unlisted":false},{"type":"link","label":"Release Process","href":"/tts-wrapper/docs/developer/releases","docId":"developer/releases","unlisted":false},{"type":"link","label":"Contributing","href":"/tts-wrapper/docs/developer/contributing","docId":"developer/contributing","unlisted":false}],"collapsed":true,"collapsible":true}]},"docs":{"api/overview":{"id":"api/overview","title":"API Overview","description":"TTS Wrapper's API is designed to be intuitive and consistent across different TTS engines. This overview will help you understand the main components and their relationships."},"developer/adding-engines":{"id":"developer/adding-engines","title":"Adding New Engines","description":"This guide explains how to add a new TTS engine to the wrapper system.","sidebar":"docs"},"developer/contributing":{"id":"developer/contributing","title":"Contributing","description":"We welcome contributions to TTS Wrapper! This guide will help you get started.","sidebar":"docs"},"developer/overview":{"id":"developer/overview","title":"Developer Overview","description":"This section provides information for developers who want to contribute to TTS Wrapper or integrate it into their projects.","sidebar":"docs"},"developer/releases":{"id":"developer/releases","title":"Release Process","description":"This guide explains how to create and manage releases for TTS Wrapper.","sidebar":"docs"},"engines/avsynth":{"id":"engines/avsynth","title":"AVSynth TTS","description":"AVSynth provides native text-to-speech capabilities on macOS using the AVSpeechSynthesizer framework. It offers high-quality system voices with real-time streaming and word timing support.","sidebar":"docs"},"engines/aws-polly":{"id":"engines/aws-polly","title":"AWS Polly","description":"Amazon Polly is a cloud-based text-to-speech service that offers high-quality voice synthesis with support for multiple languages and voices.","sidebar":"docs"},"engines/elevenlabs":{"id":"engines/elevenlabs","title":"ElevenLabs TTS","description":"ElevenLabs provides high-quality neural text-to-speech with support for voice cloning and customization. It offers some of the most natural-sounding voices available.","sidebar":"docs"},"engines/espeak":{"id":"engines/espeak","title":"espeak","description":"","sidebar":"docs"},"engines/google-cloud":{"id":"engines/google-cloud","title":"Google Cloud TTS","description":"Google Cloud Text-to-Speech provides high-quality voice synthesis with support for multiple languages, voices, and neural models.","sidebar":"docs"},"engines/googletrans":{"id":"engines/googletrans","title":"GoogleTrans TTS","description":"GoogleTrans provides free text-to-speech capabilities through Google Translate's speech synthesis. It's useful for basic TTS needs without requiring API keys or authentication.","sidebar":"docs"},"engines/ibm-watson":{"id":"engines/ibm-watson","title":"IBM Watson TTS","description":"IBM Watson Text-to-Speech provides high-quality voice synthesis with support for neural voices, SSML, and real-time streaming capabilities.","sidebar":"docs"},"engines/microsoft-azure":{"id":"engines/microsoft-azure","title":"Microsoft Azure TTS","description":"Microsoft Azure Cognitive Services Text-to-Speech provides high-quality voice synthesis with support for neural voices, custom voice creation, and extensive SSML features.","sidebar":"docs"},"engines/overview":{"id":"engines/overview","title":"TTS Engines Overview","description":"TTS Wrapper supports multiple text-to-speech engines, each with its own features, capabilities, and authentication requirements. This section provides detailed documentation for each supported engine.","sidebar":"docs"},"engines/playht":{"id":"engines/playht","title":"Play.HT TTS","description":"Play.HT provides high-quality neural text-to-speech with support for voice cloning, custom voice creation, and multiple voice engines including PlayHT 2.0 and Play3.0-mini.","sidebar":"docs"},"engines/sapi":{"id":"engines/sapi","title":"SAPI TTS","description":"SAPI (Microsoft Speech API) provides native text-to-speech capabilities on Windows systems. It offers access to installed system voices with basic SSML support.","sidebar":"docs"},"engines/sherpaonnx":{"id":"engines/sherpaonnx","title":"Sherpa-ONNX TTS","description":"Sherpa-ONNX is an open-source speech toolkit that provides offline text-to-speech capabilities using ONNX models. It's designed for applications requiring local, privacy-focused speech synthesis.","sidebar":"docs"},"engines/witai":{"id":"engines/witai","title":"Wit.ai TTS","description":"Wit.ai provides text-to-speech capabilities as part of Facebook's AI services. It offers basic speech synthesis with support for multiple languages.","sidebar":"docs"},"guides/audio-control":{"id":"guides/audio-control","title":"Audio Control","description":"TTS Wrapper provides comprehensive audio playback control features, allowing you to manage speech synthesis playback in real-time.","sidebar":"docs"},"guides/basic-usage":{"id":"guides/basic-usage","title":"Basic Usage","description":"This guide covers the fundamental operations of TTS Wrapper.","sidebar":"docs"},"guides/callbacks":{"id":"guides/callbacks","title":"Callbacks","description":"TTS Wrapper provides a simple callback system to handle speech events. There are three main callbacks available:","sidebar":"docs"},"guides/ssml":{"id":"guides/ssml","title":"SSML Support","description":"Speech Synthesis Markup Language (SSML) support in TTS Wrapper is engine-dependent. Each engine has its own SSML implementation that maps to what the underlying service supports.","sidebar":"docs"},"guides/streaming":{"id":"guides/streaming","title":"Streaming","description":"TTS Wrapper provides powerful streaming capabilities that allow you to process and play audio in real-time, making it ideal for applications requiring immediate audio feedback or handling large amounts of text.","sidebar":"docs"},"installation":{"id":"installation","title":"Installation","description":"This guide will help you install TTS Wrapper and its dependencies. The library is published on PyPI as py3-tts-wrapper but installs as tts_wrapper in your Python environment.","sidebar":"docs"},"intro":{"id":"intro","title":"Introduction","description":"Welcome to TTS Wrapper, a powerful and flexible python library that simplifies text-to-speech integration across multiple services. Whether you're building an application that needs speech synthesis capabilities or just want to experiment with different TTS engines, TTS Wrapper provides a unified interface that makes it easy to work with various text-to-speech services.","sidebar":"docs"}}}}