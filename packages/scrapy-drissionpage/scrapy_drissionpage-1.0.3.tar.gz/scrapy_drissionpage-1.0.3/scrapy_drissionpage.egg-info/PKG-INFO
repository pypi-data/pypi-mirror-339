Metadata-Version: 2.1
Name: scrapy-drissionpage
Version: 1.0.3
Summary: å°†Scrapyçˆ¬è™«æ¡†æ¶ä¸DrissionPageç½‘é¡µè‡ªåŠ¨åŒ–å·¥å…·è¿›è¡Œæ— ç¼é›†æˆ
Home-page: https://github.com/kingking888/scrapy-drissionpage
Author: KingKing888
Author-email: KingKing888 <184108270@qq.com>
License: MIT
Project-URL: Homepage, https://github.com/xyuns-cn/scrapy-drissionpage
Project-URL: Bug Tracker, https://github.com/xyuns-cn/scrapy-drissionpage/issues
Keywords: scrapy,drissionpage,crawler,spider,web scraping,automation,commercial-use,personal-use
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: License :: OSI Approved :: MIT License
Classifier: Intended Audience :: Developers
Classifier: Development Status :: 4 - Beta
Requires-Python: >=3.9
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: scrapy>=2.12.0
Requires-Dist: DrissionPage>=4.1.0.18

# Scrapy DrissionPage é›†æˆå·¥å…·

## ğŸ“Œ é¡¹ç›®ç®€ä»‹

Scrapy DrissionPage æ˜¯ä¸€ä¸ªå°† DrissionPage ä¸ Scrapy æ¡†æ¶æ— ç¼é›†æˆçš„æ‰©å±•å·¥å…·ï¼Œè®©æ‚¨å¯ä»¥åœ¨ Scrapy çˆ¬è™«ä¸­ä½¿ç”¨ DrissionPage çš„å…¨éƒ¨åŠŸèƒ½ã€‚æœ¬æ‰©å±•å·¥å…·æ”¯æŒæµè§ˆå™¨è‡ªåŠ¨åŒ–å’Œæ•°æ®åŒ…æ”¶å‘ä¸¤ç§æ¨¡å¼ï¼Œå¹¶å¯ä»¥è‡ªç”±åˆ‡æ¢ï¼Œå¤§å¹…æé«˜çˆ¬è™«å¼€å‘æ•ˆç‡ä¸ç¨³å®šæ€§ã€‚

### ä¸»è¦ç‰¹æ€§ï¼š

- ğŸŒ **æ¨¡å¼è‡ªç”±åˆ‡æ¢**ï¼šæ”¯æŒåœ¨æµè§ˆå™¨æ¨¡å¼ï¼ˆchromiumï¼‰å’Œä¼šè¯æ¨¡å¼ï¼ˆsessionï¼‰é—´åŠ¨æ€åˆ‡æ¢
- ğŸš€ **æ€§èƒ½ä¼˜åŒ–**ï¼šæä¾›æ•°æ®è¯»å–åŠ é€ŸåŠŸèƒ½ï¼Œæ”¯æŒé™æ€è§£æï¼Œæé«˜æ•°æ®æå–é€Ÿåº¦
- ğŸ“¦ **æ•°æ®åŒ…ç›‘å¬**ï¼šå¯ç›‘å¬ç½‘ç»œè¯·æ±‚ï¼Œè½»æ¾è·å–AJAXåŠ è½½çš„æ•°æ®
- ğŸ“¥ **æ–‡ä»¶ä¸‹è½½**ï¼šé›†æˆä¸‹è½½åŠŸèƒ½ï¼Œæ”¯æŒè‡ªå®šä¹‰ä¿å­˜è·¯å¾„å’Œæ–‡ä»¶å
- ğŸ” **ç®€æ´è¯­æ³•**ï¼šå…¼å®¹DrissionPageçš„ç®€æ´å…ƒç´ å®šä½è¯­æ³•ï¼Œå¤§å¤§å‡å°‘ä»£ç é‡

## ğŸ“¥ å®‰è£…æ–¹æ³•

### ä¾èµ–é¡¹

- Python 3.9+
- Scrapy 2.12.0+
- DrissionPage 4.1.0.18+

### å®‰è£…å‘½ä»¤

```bash
# å®‰è£…DrissionPage
pip install DrissionPage>=4.1.0.18

# å®‰è£…æ‰©å±•å·¥å…·
pip install scrapy-drissionpage
```

## âš™ï¸ åŸºæœ¬é…ç½®

åœ¨ Scrapy é¡¹ç›®çš„ `settings.py` ä¸­æ·»åŠ ä»¥ä¸‹é…ç½®ï¼š

```python
# å¯ç”¨ä¸­é—´ä»¶
DOWNLOADER_MIDDLEWARES = {
    'scrapy_drissionpage.middleware.DrissionPageMiddleware': 543,
}

# DrissionPageé…ç½®
DRISSIONPAGE_HEADLESS = True  # æ˜¯å¦æ— å¤´æ¨¡å¼
DRISSIONPAGE_LOAD_MODE = 'normal'  # é¡µé¢åŠ è½½æ¨¡å¼ï¼šnormal, eager, none
DRISSIONPAGE_DOWNLOAD_PATH = 'downloads'  # ä¸‹è½½è·¯å¾„
DRISSIONPAGE_TIMEOUT = 30  # è¯·æ±‚è¶…æ—¶æ—¶é—´
DRISSIONPAGE_RETRY_TIMES = 3  # é‡è¯•æ¬¡æ•°
DRISSIONPAGE_RETRY_INTERVAL = 2  # é‡è¯•é—´éš”ï¼ˆç§’ï¼‰

# æµè§ˆå™¨è®¾ç½®
DRISSIONPAGE_BROWSER_PATH = None  # æµè§ˆå™¨è·¯å¾„ï¼ŒNoneä½¿ç”¨é»˜è®¤æµè§ˆå™¨
DRISSIONPAGE_INCOGNITO = True  # æ˜¯å¦ä½¿ç”¨æ— ç—•æ¨¡å¼
DRISSIONPAGE_CHROME_OPTIONS = ['--disable-gpu']  # Chromeå¯åŠ¨é€‰é¡¹
```

## ğŸ§° ä½¿ç”¨æ–¹æ³•

### 1. åˆ›å»ºçˆ¬è™«

ç»§æ‰¿ `DrissionSpider` ç±»åˆ›å»ºçˆ¬è™«ï¼š

```python
from scrapy_drissionpage.spider import DrissionSpider

class MySpider(DrissionSpider):
    name = 'myspider'
    
    def start_requests(self):
        # åˆ›å»ºæµè§ˆå™¨æ¨¡å¼è¯·æ±‚
        yield self.drission_request(
            'https://example.com',
            page_type='chromium',  # ä½¿ç”¨æµè§ˆå™¨æ¨¡å¼
            callback=self.parse
        )
        
        # åˆ›å»ºä¼šè¯æ¨¡å¼è¯·æ±‚
        yield self.drission_request(
            'https://example.com/api',
            page_type='session',  # ä½¿ç”¨ä¼šè¯æ¨¡å¼
            callback=self.parse_api
        )
    
    def parse(self, response):
        # ä½¿ç”¨DrissionPageçš„è¯­æ³•æŸ¥æ‰¾å…ƒç´ 
        title = response.ele('tag:h1').text
        yield {'title': title}
```

### 2. æ¨¡å¼åˆ‡æ¢

æ‚¨å¯ä»¥åœ¨ä¸åŒçš„è¯·æ±‚é—´åŠ¨æ€åˆ‡æ¢æ¨¡å¼ï¼ŒDrissionPage 4.1.0.18ç‰ˆæœ¬å·²æ”¯æŒæ›´ä¾¿æ·çš„æ¨¡å¼åˆ‡æ¢ï¼š

```python
def parse_login(self, response):
    # å…ˆä½¿ç”¨æµè§ˆå™¨æ¨¡å¼ç™»å½•
    response.page.ele('#username').input('user123')
    response.page.ele('#password').input('password123')
    response.page.ele('#login-btn').click()
    
    # è·å–å½“å‰ä¼šè¯çš„sessionå¯¹è±¡å¹¶ä½¿ç”¨å®ƒå‘é€è¯·æ±‚
    session_page = self.get_utils().ModeSwitcher.to_session(response.page)
    
    # æˆ–è€…ç›´æ¥ä½¿ç”¨DrissionRequestå‘é€ä¼šè¯æ¨¡å¼è¯·æ±‚
    yield self.drission_request(
        'https://example.com/api/data',
        page_type='session',  # åˆ‡æ¢åˆ°ä¼šè¯æ¨¡å¼
        callback=self.parse_data
    )
```

### 3. æ•°æ®æå–åŠ é€Ÿ

ä½¿ç”¨ `s_ele` å’Œ `s_eles` æ–¹æ³•è¿›è¡Œé™æ€è§£æï¼Œæé«˜æ•°æ®æå–é€Ÿåº¦ï¼š

```python
def parse(self, response):
    # å¸¸è§„æ–¹å¼
    # links = response.eles('t:a')  # é€Ÿåº¦è¾ƒæ…¢
    
    # åŠ é€Ÿæ–¹å¼
    links = response.s_eles('t:a')  # é€Ÿåº¦æå‡çº¦10å€
    
    for link in links:
        yield {
            'text': link.text,
            'url': link.attr('href')
        }
```

### 4. æ•°æ®åŒ…ç›‘å¬

ç›‘å¬å’Œæ‹¦æˆªé¡µé¢ä¸Šçš„ç½‘ç»œè¯·æ±‚ï¼š

```python
def parse_with_monitor(self, response):
    # å¼€å§‹ç›‘å¬APIè¯·æ±‚
    response.page.listen.xhr(callback=self.handle_xhr)
    
    # ç‚¹å‡»æŒ‰é’®è§¦å‘AJAXè¯·æ±‚
    response.page.ele('#load-more').click()
    
    # ç­‰å¾…ä¸€æ®µæ—¶é—´è®©è¯·æ±‚å®Œæˆ
    response.wait(3)
    
    # è·å–å®Œæ•°æ®ååœæ­¢åŠ è½½ï¼ˆé€‚ç”¨äºnoneåŠ è½½æ¨¡å¼ï¼‰
    response.page.stop_loading()

def handle_xhr(self, flow):
    # å¤„ç†XHRè¯·æ±‚
    if 'api/data' in flow.request.url:
        data = flow.response.json
        # å¤„ç†æ•°æ®...
```

### 5. æ–‡ä»¶ä¸‹è½½

ä½¿ç”¨å†…ç½®çš„ä¸‹è½½åŠŸèƒ½ï¼š

```python
def parse_download(self, response):
    # è®¾ç½®ä¸‹è½½é…ç½®
    response.page.download.set_path('files')
    
    # ç‚¹å‡»ä¸‹è½½æŒ‰é’®å¹¶æŒ‡å®šæ–‡ä»¶å
    response.page.ele('#download-btn').click()
    
    # ç­‰å¾…ä¸‹è½½å®Œæˆ
    mission = response.page.wait.download_begin()
    mission.wait()
    
    yield {'file_path': mission.path}
```

## ğŸ“š é«˜çº§åŠŸèƒ½

### 1. å¤šæ ‡ç­¾é¡µæ“ä½œ

```python
def parse_multi_tabs(self, response):
    # åˆ›å»ºæ–°æ ‡ç­¾é¡µ
    tab2 = response.page.new_tab('https://example.com/page2')
    
    # ä»ç¬¬ä¸€ä¸ªæ ‡ç­¾é¡µè·å–æ•°æ®
    title1 = response.page.title
    
    # ä»ç¬¬äºŒä¸ªæ ‡ç­¾é¡µè·å–æ•°æ®
    title2 = tab2.title
    
    # åˆ‡æ¢å›åŸæ ‡ç­¾é¡µ
    response.page.activate_tab()
    
    yield {
        'title1': title1,
        'title2': title2
    }
```

### 2. iframe æ“ä½œ

```python
def parse_iframe(self, response):
    # è·å–iframeå¯¹è±¡
    iframe = response.page.get_frame('#my-iframe')
    
    # åœ¨iframeä¸­æŸ¥æ‰¾å…ƒç´ 
    data = iframe.ele('#data').text
    
    yield {'iframe_data': data}
```

### 3. æ‰§è¡ŒJavaScript

```python
def parse_with_js(self, response):
    # æ‰§è¡ŒJavaScriptä»£ç 
    result = response.page.run_js('return document.title')
    
    # ä¿®æ”¹é¡µé¢å…ƒç´ 
    response.page.run_js('document.getElementById("demo").innerHTML = "Hello JavaScript"')
    
    yield {'js_result': result}
```

## ğŸŒ° å®Œæ•´ç¤ºä¾‹

### ä¾‹1ï¼šçˆ¬å–GiteeExploreé¡µé¢é¡¹ç›®åˆ—è¡¨

```python
import scrapy
from scrapy_drissionpage.spider import DrissionSpider

class GiteeSpider(DrissionSpider):
    name = 'gitee_spider'
    
    def start_requests(self):
        yield self.drission_request(
            'https://gitee.com/explore',
            page_type='session',  # ä½¿ç”¨ä¼šè¯æ¨¡å¼å³å¯ï¼Œä¸éœ€è¦JavaScript
            callback=self.parse
        )
    
    def parse(self, response):
        # ä½¿ç”¨é™æ€è§£æåŠ é€Ÿ
        ul_ele = response.s_ele('tag:ul@text():å…¨éƒ¨æ¨èé¡¹ç›®')
        projects = ul_ele.s_eles('tag:a')
        
        for project in projects:
            # åªå¤„ç†æœ‰hrefå±æ€§çš„é“¾æ¥
            if project.attr('href') and '/explore/' not in project.attr('href'):
                yield {
                    'name': project.text,
                    'url': response.urljoin(project.attr('href'))
                }
```

### ä¾‹2ï¼šå¤„ç†éœ€è¦ç™»å½•çš„ç½‘ç«™

```python
import scrapy
from scrapy_drissionpage.spider import DrissionSpider

class LoginSpider(DrissionSpider):
    name = 'login_spider'
    
    def start_requests(self):
        yield self.drission_request(
            'https://example.com/login',
            page_type='chromium',  # ä½¿ç”¨æµè§ˆå™¨æ¨¡å¼å¤„ç†ç™»å½•
            callback=self.login
        )
    
    def login(self, response):
        # å¡«å†™ç™»å½•è¡¨å•
        response.page.ele('#username').input('your_username')
        response.page.ele('#password').input('your_password')
        response.page.ele('#login-btn').click()
        
        # ç­‰å¾…ç™»å½•æˆåŠŸï¼Œé¡µé¢è·³è½¬
        response.page.wait.url_change()
        
        # ç™»å½•æˆåŠŸåè®¿é—®ç”¨æˆ·ä¸­å¿ƒ
        yield self.drission_request(
            'https://example.com/user/dashboard',
            page_type='session',  # ç™»å½•ååˆ‡æ¢åˆ°ä¼šè¯æ¨¡å¼æé«˜æ•ˆç‡
            callback=self.parse_dashboard
        )
    
    def parse_dashboard(self, response):
        # æå–ç”¨æˆ·ä¿¡æ¯
        username = response.ele('.user-name').text
        points = response.ele('.user-points').text
        
        yield {
            'username': username,
            'points': points
        }
```

## ğŸ“‹ ç‰ˆæœ¬è¯´æ˜

### v1.0.2 (æœ€æ–°ç‰ˆ)
- ğŸš€ æ”¯æŒDrissionPage 4.1.0.18ç‰ˆæœ¬
- ğŸ›  æ›´æ–°äº†APIä½¿ç”¨æ–¹å¼ï¼Œé€‚é…æœ€æ–°çš„DrissionPageæ¥å£
- ğŸ”„ æä¾›å‘åå…¼å®¹æ€§æ”¯æŒï¼Œç¡®ä¿ä¸æ—§ç‰ˆæœ¬å…¼å®¹
- ğŸ› ä¿®å¤äº†cookiesè®¾ç½®é—®é¢˜

### v1.0.1
- ğŸ› ä¿®å¤äº†åŒ…å‘å¸ƒé…ç½®é—®é¢˜
- ğŸ”§ ä¼˜åŒ–äº†ä¾èµ–ç®¡ç†

### v1.0.0
- ğŸ‰ é¦–æ¬¡å‘å¸ƒ
- ğŸ”Œ æä¾›äº†Scrapyä¸DrissionPageçš„åŸºæœ¬é›†æˆåŠŸèƒ½

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ï¼Œå…è®¸ä¸ªäººå’Œå•†ä¸šä½¿ç”¨ã€‚

- **ä¸ªäººä½¿ç”¨**ï¼šä»»ä½•ä¸ªäººå¯ä»¥è‡ªç”±ä½¿ç”¨ã€ä¿®æ”¹å’Œåˆ†å‘æœ¬è½¯ä»¶ã€‚
- **å•†ä¸šç”¨é€”**ï¼šå…è®¸å°†æœ¬è½¯ä»¶ç”¨äºå•†ä¸šäº§å“å’ŒæœåŠ¡ï¼Œæ— éœ€æ”¯ä»˜é¢å¤–è´¹ç”¨ã€‚

æŸ¥çœ‹å®Œæ•´çš„ [LICENSE](LICENSE) æ–‡ä»¶è·å–æ›´å¤šä¿¡æ¯ã€‚

---

é€šè¿‡ä»¥ä¸Šé…ç½®å’Œç¤ºä¾‹ï¼Œæ‚¨å¯ä»¥å¼€å§‹ä½¿ç”¨Scrapy DrissionPageæ‰©å±•å·¥å…·è¿›è¡Œé«˜æ•ˆçš„ç½‘é¡µæŠ“å–ã€‚è¯¥å·¥å…·ç»“åˆäº†Scrapyçš„åˆ†å¸ƒå¼æŠ“å–èƒ½åŠ›å’ŒDrissionPageçš„å¼ºå¤§è‡ªåŠ¨åŒ–åŠŸèƒ½ï¼Œä¸ºæ‚¨æä¾›äº†ä¸€ä¸ªå¼ºå¤§è€Œçµæ´»çš„ç½‘ç»œæŠ“å–è§£å†³æ–¹æ¡ˆã€‚
