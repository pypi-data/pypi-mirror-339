# C:\Users\CRVI\OneDrive - Hall & Wilcox\promptflowcustomtools\pf-reasoning-tool-proj\pf_reasoning_tool\yamls\reasoning_tool_call.yaml

$schema: https://azuremlschemas.azureedge.net/promptflow/latest/Tool.schema.json
name: Reasoning LLM Tool # Tool name
description: "Calls an OpenAI reasoning model on Azure OpenAI using a PromptTemplate, parsing specific markers, and allowing parameter configuration."
type: custom_llm
category: HW_PF_tools
module: pf_reasoning_tool.tools.reasoning_tool_call
function: reasoning_llm # Your function name

default_prompt: |
  # system:
  You are a helpful AI assistant designed for reasoning tasks.

  # user:
  {{question}} # Example variable, adjust if needed

inputs:
  connection:
    type:
      - AzureOpenAIConnection
      - OpenAIConnection
      - CustomConnection
    description: The connection object for OpenAI or Azure OpenAI.
  deployment_name:
    type:
      - string
    description: Name of the Azure OpenAI deployment (e.g., your o3-mini deployment).
  max_completion_tokens:
    type:
      - int
    description: Maximum number of tokens for the completion.
    default: 5000
    optional: true
    ui_hints:
      text_box_size: md # Keep medium size
  reasoning_effort:
    type:
      - string
    description: Select the reasoning effort level for the model.
    default: "low"
    optional: true
    dynamic_list:
      func_path: pf_reasoning_tool.tools.reasoning_tool_call.get_reasoning_effort_options
      func_kwargs: []
    allow_manual_entry: false
    is_multi_select: false

  # ---> ADDED temperature input <---
  temperature:
    type:
      - double # Use double for float in YAML
    description: Controls randomness. Lower values make output more focused. (e.g., 0.7)
    default: 0.7
    optional: true
    ui_hints:
      text_box_size: xs # Extra small is usually fine for temperature

  # ---> ADDED response_format input <---
  response_format:
    type:
      - object # Corresponds to dict in Python
    description: 'Specify the output format (e.g., "{"type": "text"} or {"type": "json_object"}). Leave blank for default text.'
    optional: true # Make it optional, default is handled in Python
    # No 'default' here, as default behavior is handled by Python code if None
    ui_hints:
      text_box_size: lg # Large box suitable for JSON objects

outputs:
  output:
    type:
      - string
    description: The text response generated by the language model.