_target_: tracklab.wrappers.OracleDDSORT

_recursive_: False
training_enabled: True
eval_set: ${dataset.eval_set}
return_gt: False  # ignore predictions and just return ground truth detections  # /!\ ground truth detections will be skipped if a frame does not contain predictions
return_gt_ass: False  # optimally associate predictions using oracle ground truth information

train_cfg:
  use_wandb: ${use_wandb}
  use_rich: ${use_rich}
  evaluate_only: False   # activate to skip training and eval only
  model_selection_criteria: "last"  # criteria to select the best model: {best_loss, best_sim_auroc, last}
  pl_trainer:
    max_epochs: 25
    precision: 32
    gradient_clip_val: 0
    accumulate_grad_batches: 1  # 1 for no accumulation
    enable_progress_bar: True
    enable_model_summary: False
    profiler: null  # "simple" or "advanced", activate to display time profiling info
    num_sanity_val_steps: 0  # sanity run of val batches before training
    log_every_n_steps: 50  # default 50
    check_val_every_n_epochs: 1  # default 1
    val_check_interval: null  # default 1.0
    fast_dev_run: False

ddsort:
  sort:  # naive assoc()
    _target_: dd_sort.DDSORT
    _enabled_: True
    min_hits: 1  # number of hits to become a tracklet
    max_wo_hits: 100  # number of misses before removing from tracklet
    max_gallery_size: 50  # max number of observations in the gallery for each tracklet
    min_init_conf: 0.4  # minimum confidence to initialize a tracklet
#  bytetrack:  # bytetrack assoc()
#    _target_: dd_sort.DDSORTBYTETracker
#    _enabled_: True
#    det_high_thresh: 0.4  # high detection threshold
#    det_low_thresh: 0.1  # low detection threshold
#    max_time_lost: 300  # number of misses before removing from tracklet
#    max_gallery_size: 100  # max number of observations in the gallery for each tracklet
#    min_hits: 0  # number of hits to become a tracklet
#    simformer_call_strat: 1call  # {3call, 1call} 3call: call simformer 3 times, 1call: call simformer 1 time

det_filter_cfg:
  min_vis_keypoints: null  # filter on inputs of the tracker
  vis_keypoint_threshold: null  # filter on inputs of the tracker
  min_bbox_threshold: null # filter on inputs of the tracker  # TODO why different from BBSS?

checkpoint_path: null  # overrides the checkpoint_paths from the submodules
override_cfg: null  # null if you do not want to override args from the checkpoints

simformer:
  _target_: dd_sort.SimFormer

  merge_token_strat: sum  # identity sum concat
  sim_strat: iou  # cosine, iou, norm_euclidean, euclidean, default_for_each_token_type
  assos_strat: hungarian
  use_computed_threshold: false
  sim_threshold: 0.5  # sim_former similarity threshold for track/det association: pair with a similarity (in the 0->1 range) lower than this value cannot be matched. If 'null', threshold will be computed automatically.
  loss_strat: infoNCE  # {triplet; infoNCE}
  # triplet loss args
  tl_margin: 0.2  # margin for triplet loss
  contrastive_loss_strat: "inter"  # "inter": only det can be positive/negative of track and vice-versa, "inter_intra": det or track can be positive/negative of track and vice-versa
                                               # "valid_inter" or "valid_inter_intra": only valid det/track (track_ids >= 0)

  train_cfg: # AdamW  # BUSCA: reduce LR by factor 10 after 20th epoch (max = 25 epochs), MOTIP 18ep and lr divided by 20 after 10th and 16th epoch # TODO add lower lr
    init_lr: 1e-4   # BUSCA = 0.00002, MOTIP = 1e-4
    weight_decay: 0.001  # BUSCA = 1e-5, MOTIP = 5*1e-4
    alpha_loss: 1.0

  transformer_cfg:
    _target_: dd_sort.Identity  # {Identity, Encoder, Decoder, SimpleDecoder, Perceptron, Transformer}
    emb_dim: 1024  # BUSCA trans internal dim = 512 (output resnet = 512), MOTIP hidden_dim=256
    n_heads: 8  # BUSCA = 4, MOTIP = 8
    n_layers: 4  # BUSCA = 4, MOTIP = 6
    dim_feedforward: 4096  # BUSCA = 1024, MOTIP dim_feedforward = 512
    dropout: 0.1
    activation_fn: relu
    use_processed_track_tokens: True  # use the processed track tokens instead of the input ones
    src_key_padding_mask: True  # use the `src_key_padding_mask` in the transformer instead of 'src_mask'
    checkpoint_path: null  # override the weights of this module using this path
    enable_track_det_token: False # add learned tracklets/detections tokens to the input sequence
    enable_src_norm: True
    enable_src_drop: True
    enable_xavier_init: False

#  transformer_cfg:  # Perceptron to simply pass the merged tokens through a MLP
#    _target_: dd_sort.Perceptron  # {Identity, Encoder, Decoder, Perceptron}
#    checkpoint_path: null
#    emb_dim: 1024
#    n_layers: 2
#    dim_feedforward: 2048

#  transformer_cfg:
#    _target_: dd_sort.Transformer
#    emb_dim: 1024
#    n_heads: 16
#    n_e_layers: 3
#    n_d_layers: 3
#    dim_feedforward: 4096
#    dropout: 0.1
#    activation_fn: gelu
#    use_processed_track_tokens: True  # use the processed track tokens instead of the input ones
#    src_key_padding_mask: True  # use the `src_key_padding_mask` in the transformer instead of 'src_mask'
#    checkpoint_path: null  # override the weights of this module using this path


#  transformer_cfg:
#    _target_: dd_sort.EncoderWithStateTokens  # {Identity, Encoder, Decoder, Perceptron, Transformer}
#    checkpoint_path: null  # override the weights of this module using this path
#    emb_dim: 1024  # BUSCA trans internal dim = 512 (output resnet = 512), MOTIP hidden_dim=256
#    n_heads: 16  # BUSCA = 4, MOTIP = 8
#    n_layers: 3  # BUSCA = 4, MOTIP = 6
#    dim_feedforward: 4096  # BUSCA = 1024, MOTIP dim_feedforward = 512
#    dropout: 0.1
#    activation_fn: gelu
#    use_processed_track_tokens: True  # use the processed track tokens instead of the input ones
#    src_key_padding_mask: True  # use the `src_key_padding_mask` in the transformer instead of 'src_mask'
#    enable_src_norm: True  #
#    enable_src_drop: True  #
#    enable_xavier_init: False
#    enable_cls_token: True
#    repeat_special_tokens: False  # keep False

#  transformer_cfg:
#    _target_: dd_sort.EncoderWithIdTokens  # {Identity, Encoder, Decoder, SimpleDecoder, Perceptron, Transformer}
#    checkpoint_path: null  # override the weights of this module using this path
#    emb_dim: 1024  # BUSCA trans internal dim = 512 (output resnet = 512), MOTIP hidden_dim=256
#    n_heads: 16  # BUSCA = 4, MOTIP = 8
#    n_layers: 3  # BUSCA = 4, MOTIP = 6
#    dim_feedforward: 4096  # BUSCA = 1024, MOTIP dim_feedforward = 512
#    dropout: 0.1
#    activation_fn: gelu
#    use_processed_track_tokens: True  # use the processed track tokens instead of the input ones
#    src_key_padding_mask: True  # use the `src_key_padding_mask` in the transformer instead of 'src_mask'
#    enable_track_det_token: False  # add learned tracklets/detections tokens to the input sequence
#    enable_src_norm: True  #
#    enable_src_drop: True  #
#    enable_cls_token: True  #
#    enable_xavier_init: False
#    max_track_ids: 200
#    max_det_ids: 200
#    enable_encoder: True
#    enable_sum_tokens: False  # sum cues token at the beginning
#    enable_id_tokens: True
#    id_tokens_fusion_mode: sum # concat sum
#    enable_input_id_tokens: True
#    use_id_tokens_as_embeddings: False
#    output_mode: "average_all_tokens"  # standard reid_tokens motion_tokens average_cues_tokens average_all_tokens


  # Declare the list of tokenizers to use here. Tokenizer key is arbitrary
  tokenizers_cfg:
    LinearAppearance:
      _target_: dd_sort.LinearAppearance
      _enabled_: False
      enable_ll: True
      token_dim: ${...transformer_cfg.emb_dim}
      feat_dim: 128
      agg_strat: ema  # {ema, mean, last}
      checkpoint_path: null  # override the weights of this module using this path
      alpha: 0.1
      only_foreground: True
    #SmartLinearAppearance:
    #  _target_: dd_sort.SmartLinearAppearance
    #  _enabled_: False
    #  enable_ll: True
    #  checkpoint_path: null  # override the weights of this module using this path
    #  token_dim: ${...transformer_cfg.emb_dim}
#      feat_dim: 128
#      alpha: 0.9  # reversed compared to ema LinearAppearance
#      only_foreground: True
    #MotionBertTokenizer:
    #  _target_: dd_sort.MotionBertTokenizer
    #  _enabled_: False
    #  checkpoint_path: ${model_dir}/MotionBERT/motionbert_42085620_still-dawn-1446.ckpt  # override the weights of this module using this path
    #  mb_checkpoint_path: ${model_dir}/MotionBERT/motionbert_lite.bin  # init weights for training
    #  freeze: False
    #  token_dim: ${...transformer_cfg.emb_dim}
    #  agg_strat: ema
    #  pad_empty_frames: True  # Will pad each empty frame with 0s if True, or use a concatenation of all available skeletons if False
    #  tracklet_max_age: 20  # Will use skeletons until this number of frames in the past, padding with 0s when necessary
    LastBboxTokenizer:
      _target_: dd_sort.LastBboxTokenizer
      _enabled_: False
      checkpoint_path: null  # override the weights of this module using this path
      freeze: False
      feat_dim: 4
      token_dim: ${...transformer_cfg.emb_dim}
      hidden_channels: [256]
      no_mlp: False
    KFTokenizer:
      _target_: dd_sort.KFTokenizer
      _enabled_: True
      checkpoint_path: null  # override the weights of this module using this path
      freeze: False
      feat_dim: 4
      max_length: 10
      kf_orig: True
      kf_mode: "BBSS"  # KalmanBoxTracker BBSS
      use_confidence: False
      token_dim: ${...transformer_cfg.emb_dim}
      hidden_channels: [ 256 ]
      no_mlp: True
#    KFTokenizer:
#      _target_: dd_sort.KFTokenizer
#      _enabled_: True
#      checkpoint_path: null  # override the weights of this module using this path
#      freeze: False
#      feat_dim: 4
#      token_dim: ${...transformer_cfg.emb_dim}
#      hidden_channels: [ 256 ]
#      no_mlp: False

    TrackletEncoder:
      _target_: dd_sort.TrackletEncoder
      _enabled_: False
      _recursive_: false
      hidden_dim: 512
      output_dim: ${...transformer_cfg.emb_dim}
      n_heads: 4
      n_layers: 4
      dim_feedforward: 1024
      num_registers: 0
      dropout: 0.1
      checkpoint_path: null  # override the weights of this module using this path
      occlusion_threshold: null  # mark occluded detections with a special token if iou is higher than threshold (null is no marking)
      pass_detections: true  # pass also the detections into the encoder
      output_strat: cls  # {cls, mean}
      use_pe : true
      use_drop: true
      use_norm: true  # use normalization before the encoder
      freeze: false  # freeze the weights
      det_tokenizer:
        _target_: dd_sort.DetTokenizer
        feats_tokenizers:
          #- _target_: dd_sort.BBoxLinProj
          #  use_conf: true
          #- _target_: dd_sort.KeypointsLinProj
          #  use_conf: false
          - _target_: dd_sort.EmbeddingsLinProj
            use_parts: true

  classifier_cfg: null
    # null for no classifier
    #_target_: dd_sort.LinearClassifier
    #_enabled_: True
    #emb_dim: ${..transformer_cfg.emb_dim}
    #checkpoint_path: null  # override the weights of this module using this path
    #_target_: dd_sort.MLPClassifier
    #_enabled_: False
    #checkpoint_path: null  # override the weights of this module using this path
    #emb_dim: ${..transformer_cfg.emb_dim}
    #hidden_dim: # must be a list that finishes with 1
    #  - 128
    #  - 1
    #activation_fn: relu
    #dropout: ${..transformer_cfg.dropout}

datamodule:
  _target_: dd_sort.SimFormerDataModule

  ## Training parameters
  sampler: "simple"  # simple/occlusion/gap
  sampler_args:
    fill_samples: true # for simple, don't add padding, but use another sample
    # window_size: 5 # for occlusion, sum of occlusions from how many frames before are taken into account
    # min_iou: 0.25 # for occlusion, minimum IoU to count as an occlusion
    # prob_occlusion_sampling: 1.0 # for occlusion, probability of sampling from the occlusion distribution
  num_videos: null # how many videos you want samples from, null for all
  num_workers: ${num_cores}
  # Params impacting the size of a training sample:
  max_length: 100  # max number of detections for a tracklet (keep 'max_length' most recent detections in a tracklet after all transforms have been applied to it)
  # Params impacting the size of a batch:
  batch_size: 32  # number of training samples in a batch. A training samples = a data association example in a given frame (i.e. a similarity matrix representing a single online tracking step)
  num_samples: 32  # number of tracklets/dets pairs in a training sample
  # Params impacting the size of an epoch:
  samples_per_video: 100  # number of frame per video
  train_add_val: False

  tracklet_transforms: # transformers related to one pair tracklet-det
    train:
      _target_: dd_sort.simformer.transforms.Compose
      transforms:
        - _target_: dd_sort.simformer.transforms.MaxNumObs
          max_num_obs: 150  # 5 secs
        - _target_: dd_sort.simformer.transforms.ProbabilisticTransform
          probs: [ 0.9, 0.25, 0.1, 0.1 ]
          transforms:
            - _target_: dd_sort.simformer.transforms.SwapSporadic
              p_swap: 0.4  # probability of swapping a detection from the tracklet
              sigma: 50  # falling rate of the gaussian distribution
              method: "gaussian" # {gaussian, uniform}
              not_on_most_recent_image: ${modules.track.simformer.tokenizers_cfg.LastBboxTokenizer._enabled_}
            - _target_: dd_sort.simformer.transforms.SwapOccluded
              p_swap: 0.2  # probability of swapping an occluded detection
              min_iou: 0.2  # iou threshold to consider two detections as occluded
              not_on_most_recent_image: ${modules.track.simformer.tokenizers_cfg.LastBboxTokenizer._enabled_}
#            - _target_: dd_sort.simformer.transforms.SwapRandomDetections
#              p_swap: 0.1
#              max_swap_prop: 0.3  # cannot have more than 30% swapped det inside tracklet (to avoid too much corrupt)
#              not_on_most_recent_image: ${modules.track.simformer.tokenizers_cfg.LastBboxTokenizer._enabled_}
            - _target_: dd_sort.simformer.transforms.DropoutOccluded
              p_drop: 0.2 # probability of dropping a detection if it was occluded
              min_iou: 0.5 # IoU threshold to consider occlusions
            - _target_: dd_sort.simformer.transforms.DropoutSporadic
              p_drop: 0.5  # probability of dropping a detection from the tracklet
              sigma: 50  # falling rate of the gaussian distribution
              method: "gaussian" # {gaussian, uniform}
    #val: ${.train}
  batch_transforms:
    train:
      _target_: dd_sort.simformer.transforms.Compose
      transforms:
        - _target_: dd_sort.simformer.transforms.AppEmbNoise
          alpha: 0.4
        - _target_: dd_sort.simformer.transforms.KeypointsShake
          alpha: 0.05
        - _target_: dd_sort.simformer.transforms.BBoxShake
          alpha: 0.05
    #val: ${.train}

  ## Dataset generation (for the .pklz files)
  dataset_splits: # should be a list containing train/val/test
    - train
    - val
  name: ddsort-dancetrack  # name of the file for the gallery pickle
  path: ${project_dir}/states # absolute path, otherwise it will be created for each job
  tracker_states:
    train: "${project_dir}/states/dancetrack-train.pklz"
    val: "${project_dir}/states/dancetrack-val.pklz"
  multi_dataset_training: null # [sportsmot, dancetrack] # don't repeat main dataset here !
  dataset_paths:
    dancetrack:
      name: ddsort-kpr-dancetrack
      path: ${datasets.dancetrack.dataset_path}/states/simformer_training4
      tracker_states:
        train: "${datasets.dancetrack.dataset_path}/states/kpr/train-my_det-hrnetposetrack18-kpr-ocsort2.pklz"
        val: "${datasets.dancetrack.dataset_path}/states/kpr/val-my_det-hrnetposetrack18-kpr-ocsort2.pklz"
#    sportsmot:
#      name: ddsort-kpr-sportsmot
#      path: ${datasets.sportsmot.dataset_path}/states/simformer_training4
#      tracker_states:
#        train: "${datasets.sportsmot.dataset_path}/states/kpr/train-public_dets-hrnetposetrack18-kpr-ocsort2.pklz"
#        val: "${datasets.sportsmot.dataset_path}/states/kpr/val-public_dets-hrnetposetrack18-kpr-ocsort2.pklz"
  dataset_transforms:
    - add_detections
    - add_last_obs_counter
    - add_occlusions
    #- add_gt_poses  # apply pose model on GT bbox
    #- add_gt_reid_embeddings  # apply reid model on GT bbox
    #- add_crops  # add image in pklz, not do
    #- add_detections_with_id_switch  # fixme broken
    - normalize2image  # normalize bbox, always keep last

#callbacks:
#  - _target_: dd_sort.simformer.callbacks.visualization.VisualizeTrackletBatches
#    steps: # "train", "val"
#      train: 5 # null to visualize all, otherwise first N
#      val: 5
#    max_batch_size: null
#    max_frames: null