{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfejMHs4lr8V"
   },
   "source": [
    "*Copyright 2024 The Penzai Authors.*\n",
    "\n",
    "*Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at*\n",
    "\n",
    "> http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "*Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or  implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USGIPdLYDzSo"
   },
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/google-deepmind/penzai/blob/main/notebooks/how_to_think_in_penzai.ipynb) [![Open in Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/google-deepmind/penzai/blob/main/notebooks/how_to_think_in_penzai.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2VR1iZX8oUH_"
   },
   "source": [
    "# How to Think in Penzai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yK4NS1yoe_X"
   },
   "source": [
    "Penzai prioritizes legibility, visualization, and easy editing of neural network models. It strives to follow a simple mental model, avoid magic wherever possible, and decompose into modular tools that can be combined without getting in your way. This means that Penzai models are often structured somewhat differently than models written with other libraries.\n",
    "\n",
    "This document explains the key principles of Penzai's neural network system.\n",
    "\n",
    "(Note: The current \"V2\" neural network system differs from the \"V1\" neural network system in Penzai's initial release. For a summary of the differences, see [this page](/guides/v2_differences).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XGZH58j8mPkj"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  import penzai\n",
    "except ImportError:\n",
    "  !pip install penzai[notebook]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PGansFBXFes2"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import dataclasses\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from typing import Any, Callable, Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uWNMzWrBvgAX"
   },
   "outputs": [],
   "source": [
    "import treescope\n",
    "import penzai\n",
    "from penzai import pz\n",
    "from penzai.models import simple_mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JtySZ1ofS7l-"
   },
   "source": [
    "## Principles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Py-jS4vpxDT"
   },
   "source": [
    "### 1. What You See is What You Get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGMfKdCnK11t"
   },
   "source": [
    "The first central principle of Penzai is that models are designed to be visualizable by default.\n",
    "\n",
    "Penzai integrates with [Treescope](https://treescope.readthedocs.io/en/stable/), a powerful interactive IPython pretty-printer with automatic embedded array visualizations. (In fact, Treescope was originally designed as the pretty-printer for Penzai!) You can enable Treescope like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5P0luQouK1nU"
   },
   "outputs": [],
   "source": [
    "treescope.basic_interactive_setup(autovisualize_arrays=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wVz_WgmvEoHk"
   },
   "source": [
    "Penzai goes out of its way to make sure that the pretty-printer representation of a model tells you everything you need to know about it:\n",
    "\n",
    "- Every sublayer of the model is directly contained in its parent, and can be viewed by expanding it.\n",
    "- Every parameter is an attribute of the layer that owns it, and all attributes are statically known and type-annotated.\n",
    "- Most model objects are immutable, and all stateful modifications are constrained to explicit \"Variable\" objects.\n",
    "\n",
    "For instance, here's what a simple MLP looks like in Penzai:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qr7-zSPHE0Nl"
   },
   "outputs": [],
   "source": [
    "mlp = simple_mlp.MLP.from_config(\n",
    "    name=\"mlp\",\n",
    "    init_base_rng=jax.random.key(0),\n",
    "    feature_sizes=[8, 32, 32, 8]\n",
    ")\n",
    "mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jQ3XX08DE8Zd"
   },
   "source": [
    "Try clicking to expand or collapse different sublayers! We've turned on automatic array visualization, so if you expand one of the parameters, you can immediately visualize its shape and array data.\n",
    "\n",
    "Importantly, this isn't just a pretty visualization of the model, it's actually a **full specification of the model structure**. In fact, if you remove the parameters first, you can copy and paste the pretty printed output to rebuild the model structure! Every attribute of the model object appears in the pretty printed output, so if it doesn't show up in the pretty-printed output, it's not part of the model.\n",
    "\n",
    "(Tip: You can click on a pretty-printed output and press `r` to add qualified names to every type.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MB9F0pQzoZpp"
   },
   "outputs": [],
   "source": [
    "# Try clicking the output below and pressing `r`!\n",
    "unbound_mlp, _ = pz.unbind_params(mlp)\n",
    "unbound_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eb-7dilWorJB"
   },
   "outputs": [],
   "source": [
    "# Copying and pasting this pretty-printed output rebuilds the model:\n",
    "copied = penzai.models.simple_mlp.MLP( # Sequential\n",
    "  sublayers=[\n",
    "    penzai.nn.linear_and_affine.Affine( # Sequential\n",
    "      sublayers=[\n",
    "        penzai.nn.linear_and_affine.Linear(weights=penzai.core.variables.ParameterSlot(label='mlp/Affine_0/Linear.weights'), in_axis_names=('features',), out_axis_names=('features_out',)),\n",
    "        penzai.nn.linear_and_affine.RenameAxes(old=('features_out',), new=('features',)),\n",
    "        penzai.nn.linear_and_affine.AddBias(bias=penzai.core.variables.ParameterSlot(label='mlp/Affine_0/AddBias.bias'), new_axis_names=()),\n",
    "      ],\n",
    "    ),\n",
    "    penzai.nn.basic_ops.Elementwise(fn=jax.nn.relu),\n",
    "    penzai.nn.linear_and_affine.Affine( # Sequential\n",
    "      sublayers=[penzai.nn.linear_and_affine.Linear(weights=penzai.core.variables.ParameterSlot(label='mlp/Affine_1/Linear.weights'), in_axis_names=('features',), out_axis_names=('features_out',)), penzai.nn.linear_and_affine.RenameAxes(old=('features_out',), new=('features',)), penzai.nn.linear_and_affine.AddBias(bias=penzai.core.variables.ParameterSlot(label='mlp/Affine_1/AddBias.bias'), new_axis_names=())],\n",
    "    ),\n",
    "    penzai.nn.basic_ops.Elementwise(fn=jax.nn.relu),\n",
    "    penzai.nn.linear_and_affine.Affine( # Sequential\n",
    "      sublayers=[penzai.nn.linear_and_affine.Linear(weights=penzai.core.variables.ParameterSlot(label='mlp/Affine_2/Linear.weights'), in_axis_names=('features',), out_axis_names=('features_out',)), penzai.nn.linear_and_affine.RenameAxes(old=('features_out',), new=('features',)), penzai.nn.linear_and_affine.AddBias(bias=penzai.core.variables.ParameterSlot(label='mlp/Affine_2/AddBias.bias'), new_axis_names=())],\n",
    "    ),\n",
    "  ],\n",
    ")\n",
    "\n",
    "copied == unbound_mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43L1P9r4p2pV"
   },
   "source": [
    "### 2. Models Are Callable, Patchable Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ko2QuWmJF877"
   },
   "source": [
    "To make it easier to inspect and modify models, Penzai prioritizes treating models as user-modifiable data structures, rather than as opaque objects.\n",
    "Every Penzai model object is a frozen [Python dataclass](https://docs.python.org/3/library/dataclasses.html), which means that all of the instance variables of Penzai models are explicitly type-annotated and tracked.\n",
    "\n",
    "Models can be called with an input argument in order to run the model forward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bLahyDi6NVBL"
   },
   "outputs": [],
   "source": [
    "mlp(pz.nx.ones({\"features\": 8}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4TNUyCzNZV2"
   },
   "source": [
    "You can also just as easily call one of their sublayers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9wqJuLtXNfkz"
   },
   "outputs": [],
   "source": [
    "mlp.sublayers[2].sublayers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xzcjwkVJNMmX"
   },
   "outputs": [],
   "source": [
    "mlp.sublayers[2].sublayers[0](pz.nx.ones({\"features\": 32}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Er0JhNVzF3mD"
   },
   "source": [
    "However, you can also easily modify the model forward pass by modifying the model data structure.\n",
    "\n",
    "Penzai models are designed to be freely modified after they are built, including isolating small parts of larger models, combining models together, or inserting arbitrary logic at arbitrary points in a model's forward pass. And Penzai includes a structure-rewriting utility, `pz.select`, which lets you make arbitrary modifications to Penzai models using `.at(...).set(...)`-style syntax. For instance, you can find and remove particular layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EoWmFsAfGmmZ"
   },
   "outputs": [],
   "source": [
    "# Find bias layers\n",
    "pz.select(mlp).at_instances_of(pz.nn.AddBias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QFdgMdOhLovO"
   },
   "outputs": [],
   "source": [
    "# Remove them:\n",
    "pz.select(mlp).at_instances_of(pz.nn.AddBias).remove_from_parent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKzfMGgqGm2E"
   },
   "source": [
    "Or insert new layers to run new logic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mo4gGbscGqLA"
   },
   "outputs": [],
   "source": [
    "@pz.pytree_dataclass\n",
    "class HelloWorld(pz.nn.Layer):\n",
    "  def __call__(self, arg, **side_inputs):\n",
    "    pz.show(\"Hello world! My value:\", arg)\n",
    "    return arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1xMgPsdzL1Wm"
   },
   "outputs": [],
   "source": [
    "# Insert a new layer after each nonlinearity:\n",
    "patched = (\n",
    "    pz.select(mlp).at_instances_of(pz.nn.Elementwise).insert_after(HelloWorld())\n",
    ")\n",
    "pz.select(patched).at_instances_of(HelloWorld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53OjRmwSMIaQ"
   },
   "outputs": [],
   "source": [
    "# Run it:\n",
    "patched(pz.nx.ones({\"features\": 8}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PnqYMGJgGrut"
   },
   "source": [
    "Penzai models are registered as [JAX Pytree nodes](https://jax.readthedocs.io/en/latest/pytrees.html) (similar to Equinox) so that any Penzai model can be traversed using `jax.tree_util`. In fact, the `pz.select` utility is a general-purpose utility for modifying any JAX Pytree! Modifications to Penzai models always occur by making a *modified copy* of the model, instead of being stored as global state. For instsance, the model `patched` above is a modified copy of `mlp`, which behaves differently when it is run.\n",
    "\n",
    "Penzai models are also designed to be *as permissive as possible* about their contents after construction. For instance, the MLP class doesn't specifically require it's children to be Affine layers (a.k.a. Dense layers), and doesn't run the activation functions directly. Instead, it is a subclass of `Sequential`, and it just runs its sublayers in sequence without caring about their types. This means we are free to insert new logic into an `MLP` at runtume to customize its behavior, without having to change its original code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JSHu-Qdm6enb"
   },
   "source": [
    "### 3. Parameters And State Are Tracked With Explicit Variable Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COZwtGOA6sON"
   },
   "source": [
    "As Pytree nodes, Penzai model objects are immutable, which simplifies working with JAX and allows you to safely make copies of your model that behave in different ways. However, models often require keeping track of mutable state:\n",
    "- Parameters are often updated by gradient descent, and shared parameters need to stay in sync.\n",
    "- Some model configurations, like key-value caching in Transformers, require keeping track of per-layer model states while the model runs.\n",
    "- It can be useful to save intermediate model activations so that you can inspect or modify them later.\n",
    "\n",
    "Penzai supports this using \"variable\" nodes, which are explicit \"pockets of mutable state\" inside Penzai models. Each Penzai model tree has two types of leaves:\n",
    "- JAX arrays and scalars, which are immutable and often represent hyperparameters, and\n",
    "- Variable objects, which can be modified, and come in two variants:\n",
    "  - `Parameter`s, which are usually modified by optimizers (not by the model),\n",
    "  - `StateVariable`s, which are usually updated as the model runs.\n",
    "\n",
    "For instance, the leaves of the `mlp` above are its parameters, each of which is an instance of `Parameter`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "61FUfDhIF8mS"
   },
   "outputs": [],
   "source": [
    "jax.tree_util.tree_leaves(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FRfznv9FyCP"
   },
   "source": [
    "The same parameter can appear multiple times in a single model. As an example, here's a model that repeats the same layer multiple times, along with a scaling factor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Usg4ucYiMtTo"
   },
   "outputs": [],
   "source": [
    "layer = pz.nn.Affine.from_config(\n",
    "    name=\"shared_layer\",\n",
    "    init_base_rng=jax.random.key(0),\n",
    "    input_axes={\"features\": 8},\n",
    "    output_axes={\"features\": 8},\n",
    ")\n",
    "my_model_with_repeats = pz.nn.Sequential([\n",
    "    layer,\n",
    "    pz.nn.Elementwise(jax.nn.relu),\n",
    "    pz.nn.ConstantRescale(0.5),\n",
    "    layer,\n",
    "])\n",
    "my_model_with_repeats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KF2TkE9QNOJY"
   },
   "source": [
    "In this case, the PyTree leaves of this model will repeat the parameters twice, and also include the rescaling hyperparameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oIYJ05wBNXC1"
   },
   "outputs": [],
   "source": [
    "jax.tree_util.tree_leaves(my_model_with_repeats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xUCEPngINsf4"
   },
   "source": [
    "To extract and deduplicate the parameters, you can use the helper function `pz.unbind_params`. This produces:\n",
    "- A copy of the model with each `Parameter` replaced with a `ParameterSlot` placeholder,\n",
    "- A tuple of all unique parameters in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZTQeazt_OJQT"
   },
   "outputs": [],
   "source": [
    "unbound_model, params = pz.unbind_variables(my_model_with_repeats)\n",
    "\n",
    "pz.show(\"unbound_model:\", unbound_model)\n",
    "pz.show(\"params:\", params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYh53T1x_dsp"
   },
   "source": [
    "These parameters can then be substituted back into the model using `pz.bind_variables`.\n",
    "\n",
    "You can implement stateful layers using a similar mechanism, but with `StateVariable` instead of `Parameter`. Here's a layer that stores its intermediate activation into a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3fsuVKpb_5dh"
   },
   "outputs": [],
   "source": [
    "@pz.pytree_dataclass\n",
    "class SaveIntermediate(pz.nn.Layer):\n",
    "  saved: pz.StateVariable[list[Any]]\n",
    "  def __call__(self, x: Any, **unused_side_inputs) -> Any:\n",
    "    self.saved.value = self.saved.value + [x]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GIYROJQ-BaKF"
   },
   "source": [
    "We can insert two copies of it into our MLP, and then call it to retrieve the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wT33K756AH0H"
   },
   "outputs": [],
   "source": [
    "var = pz.StateVariable(value=[], label=\"my_intermediate\")\n",
    "\n",
    "saving_model = (\n",
    "    pz.select(mlp)\n",
    "    .at_instances_of(pz.nn.Elementwise)\n",
    "    .insert_after(SaveIntermediate(var))\n",
    ")\n",
    "\n",
    "saving_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tRKCIxTCA9K7"
   },
   "outputs": [],
   "source": [
    "saving_model(pz.nx.ones({\"features\": 8}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77QUE716BiS8"
   },
   "outputs": [],
   "source": [
    "var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N344WHx7BmR4"
   },
   "source": [
    "You can similarly unbind state variables using `pz.unbind_state_vars`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6HnuBnjBx1j"
   },
   "outputs": [],
   "source": [
    "unbound_saving_mlp, all_vars = pz.unbind_state_vars(saving_model)\n",
    "\n",
    "pz.show(\"unbound_saving_mlp:\", unbound_saving_mlp)\n",
    "pz.show(\"all_vars:\", all_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "btkvxTL6O0k6"
   },
   "source": [
    "Or unbind both parameters and states using `pz.unbind_variables`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3TwMCFrrO3D5"
   },
   "outputs": [],
   "source": [
    "unbound_saving_mlp, all_vars = pz.unbind_variables(saving_model)\n",
    "\n",
    "pz.show(\"unbound_saving_mlp:\", unbound_saving_mlp)\n",
    "pz.show(\"all_vars:\", all_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "058Bt2apCP0S"
   },
   "source": [
    "To make it easier to manipulate variables with JAX, any variable can be \"frozen\" using the `.freeze` method or the `pz.freeze_variables` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tsN6B0EhCKWT"
   },
   "outputs": [],
   "source": [
    "pz.freeze_variables(all_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8lkmuMGCjXv"
   },
   "source": [
    "Frozen variables are JAX PyTrees, and can be safely passed through JAX transformations. Penzai models also support a \"pure\" interface that lets you pass frozen variables in and get new frozen variables out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "owtX7l--DU2W"
   },
   "outputs": [],
   "source": [
    "# Freeze parameters:\n",
    "frozen_param_model = pz.freeze_params(saving_model)\n",
    "\n",
    "# Unbind and freeze state vars:\n",
    "unbound_frozen_model, state_vars = pz.unbind_state_vars(\n",
    "    frozen_param_model, freeze=True\n",
    ")\n",
    "state_var_values = pz.freeze_state_vars(state_vars)\n",
    "\n",
    "# Call it in \"pure\" style, tracking modifications to the intermediates variable.\n",
    "# The input and output variables are frozen, but the variable can be locally\n",
    "# modified while the model runs:\n",
    "output, updated_var_states = unbound_frozen_model.stateless_call(\n",
    "    [pz.StateVariableValue(label='my_intermediate', value=[])],\n",
    "    pz.nx.ones({\"features\": 8})\n",
    ")\n",
    "pz.show(\"output:\", output)\n",
    "pz.show(\"updated_var_states:\", updated_var_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rcRaXfGGP43"
   },
   "source": [
    "You may need to freeze variables in order to pass them through JAX's function transformations. (For `jit`, Penzai includes a wrapped version called `pz.variable_jit` that handles this for you.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YEoCzrzxqPc0"
   },
   "source": [
    "### 4. Each Layer Has The Same Signature And Does A Single Thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lug_y9o-j5jS"
   },
   "source": [
    "Penzai models are built by composing layers, where each layer implements the following interface:\n",
    "\n",
    "```python\n",
    "class Layer(pz.Struct, abc.ABC):\n",
    "  @abc.abstractmethod\n",
    "  def __call__(self, argument: Any, /, **side_inputs) -> Any:\n",
    "    ...\n",
    "\n",
    "```\n",
    "\n",
    "In short:\n",
    "\n",
    "- Each layer defines a method `__call__`, which enables it to be called directly like a function, and which contains all of the layer's runtime logic.\n",
    "- `__call__` always takes exactly one positional argument, which is its input from the previous layer. (If necessary, this argument can be a tuple, dictionary, `pz.Struct`, or other JAX Pytree.)\n",
    "- `__call__` also takes an arbitrary number of keyword arguments, which are *side inputs*. Side inputs can be used for information like attention masks or random number generators, and are usually shared across every layer in the model. Layers should ignore side inputs that they do not recognize.\n",
    "- Whenever possible, idiomatic Penzai models should not contain Python conditional branches in their `__call__`. You should be able to JIT-compile the `__call__` of any model, and there should generally be only a single control flow path through it.\n",
    "\n",
    "Penzai uses this convention because it makes it straightforward to compose layers with each other. For instance, there's an unambiguous way to run two layers in order: pass the output of the first layer as the positional input of the second, and pass the same side inputs to both layers.\n",
    "\n",
    "This means that, instead of passing configuration data as arguments to the forward pass of each layer, most configuration is directly attached to the layer itself:\n",
    "- Configuration metadata, such as the input or output axis names for `pz.nn.Linear`, the activation function for `pz.nn.Elementwise`, or the name of a dynamic side input, are stored as attributes on the layer, and set when the layer is initially built.\n",
    "- Different \"modes\" of computation, such as \"whether or not we should enable dropout\" or \"whether we are doing scoring or autoregressive decoding\", are usually represented as *different classes*. This makes sure that the number of configuration attributes is small, and that the implementation of each layer is simple. You can then swap out model components using `pz.select` to switch between different model behaviors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4JSPZXyz7Bo"
   },
   "source": [
    "The emphasis on \"doing one thing\" also extends to composite layers. In Penzai, composite layers are usually defined as direct compositions of simpler layers, by subclassing the `pz.nn.Sequential` combinator. Then, their responsibility at runtime is just to call their children in sequence, which means it's easy to insert new logic without interfering with the model's computation. We've already seen an example of this: the `MLP` model and `Affine` blocks in our `mlp` are both subclasses of `pz.nn.Sequential`.\n",
    "\n",
    "More complex combinators also tend to adhere to this pattern. For instance, the core `Attention` block in Penzai is purely a dataflow combinator, defined as\n",
    "\n",
    "```python\n",
    "@struct.pytree_dataclass\n",
    "class Attention(Layer):\n",
    "  input_to_query: Layer\n",
    "  input_to_key: Layer\n",
    "  input_to_value: Layer\n",
    "  query_key_to_attn: Layer\n",
    "  attn_value_to_output: Layer\n",
    "\n",
    "  def __call__(self, x: NamedArray, **side_inputs) -> NamedArray:\n",
    "    query = self.input_to_query(x, **side_inputs)\n",
    "    key = self.input_to_key(x, **side_inputs)\n",
    "    value = self.input_to_value(x, **side_inputs)\n",
    "    attn = self.query_key_to_attn((query, key), **side_inputs)\n",
    "    output = self.attn_value_to_output((attn, value), **side_inputs)\n",
    "    return output\n",
    "```\n",
    "\n",
    "All of the specific logic of computing positional embeddings, applying attention masks, and computing the softmax weights are left to the child layers, which makes it easy to go in and capture intermediates or intervene on their behaviors at any point, without needing to change the attention implementation. `Attention` itself just does a single thing: manage the routing of data between the different components, during training or scoring mode.\n",
    "\n",
    "If you want to do autoregressive decoding, you can swap out `Attention` blocks for `KVCachingAttention` blocks using something like\n",
    "```python\n",
    "(\n",
    "  pz.select(model)\n",
    "  .at_instances_of(pz.nn.Attention)\n",
    "  .apply(lambda attn: pz.nn.KVCachingAttention.from_uncached(attn, **kwargs))\n",
    ")\n",
    "```\n",
    "This produces a copy of your model that additionally manages and updates KV caches, while still supporting arbitrary child layer logic and without changing any of the rest of your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idaVcjoOqYVp"
   },
   "source": [
    "### 5. Configuration Happens During Construction (Not `__call__`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "waiPbkQp3tK8"
   },
   "source": [
    "As discussed above, Penzai layers avoid passing configuration arguments at runtime, and avoid making assumptions about their child layers and parameters as much as possible. However, it's still important for layers and models to be able to configure themselves and initialize their parameters. In Penzai, all of this happens when the layers are initially constructed.\n",
    "\n",
    "By convention, Penzai layers configure themselves using a class method, often called `from_config(cls, name: str, init_base_rng, ...)`. `from_config`, in turn, takes all of the configuration arguments that are necessary to initialize the model, and uses them to set up their sublayers and parameters. Penzai layers usually do NOT override `__init__`, so that it's easy to bypass the initialization logic and rebuild models with different attributes.\n",
    "\n",
    "We can see this by calling the `from_config` method of `simple_mlp.MLP`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vtULzQEF8igb"
   },
   "outputs": [],
   "source": [
    "mlp = simple_mlp.MLP.from_config(\n",
    "    name=\"mlp\",\n",
    "    init_base_rng=jax.random.PRNGKey(1),\n",
    "    feature_sizes=[8, 32, 32, 8],\n",
    "    activation_fn=jax.nn.gelu,\n",
    ")\n",
    "mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yA4upAwA8mai"
   },
   "source": [
    "Notice that the arguments to `from_config` aren't actually stored on the `MLP` itself. Instead, they are simply used to configure and set up the list of sublayers. In general, the configuration arguments of complex models will often \"vanish\" in this way after the model is initially built.\n",
    "\n",
    "In fact, all of the custom logic of `MLP` and `Affine` is defined in the `from_config` methods, not `__call__`. Once initialized, you are free to remove them entirely without affecting the behavior of the model. For instance, we can replace the MLP class with a basic `Sequential` and get the same behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kAiEAPgU9KQ4"
   },
   "outputs": [],
   "source": [
    "pz.nn.inline_groups(\n",
    "    pz.nn.Sequential([mlp]),\n",
    "    parent_filter=lambda _: True,\n",
    "    child_filter=lambda _: True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7n-su7n93Ur"
   },
   "source": [
    "This pattern also applies to layers that are designed for hot-swapping. For instance, the `KVCachingAttention` block defines a classmethod `.from_uncached` that converts an `Attention` block into a `KVCachingAttention`, which takes ownership of the children of that `Attention` block and then discards the original block.\n",
    "\n",
    "In general, it may be useful to think of a Penzai model as a \"declarative\" *list of steps in the model's forward pass*. If different configurations run different steps, they are usually represented as models with different structures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6huk4w_NC-Q"
   },
   "source": [
    "By convention, layer builders like `from_config` follow the signature\n",
    "\n",
    "```python\n",
    "def from_config(cls, name: str, init_base_rng: jax.Array | None, ...):\n",
    "  ...\n",
    "```\n",
    "\n",
    "The `name` argument is used to ensure that all parameters have unique names, and the `init_base_rng` determines how to initialize the parameters:\n",
    "- If `init_base_rng` is a JAX PRNGKey, it is combined with the `name` argument to initialize the parameter randomly. The resulting model will contain\n",
    "a `Variable` for each parameter.\n",
    "- If `init_base_rng` is `None`, parameter initialization is skipped, and the resulting model will instead contain a `VariableSlot` for each parameter. This can be useful for loading pretrained models from checkpoints instead of initializing them from scratch.\n",
    "\n",
    "To make this work:\n",
    "- Layers that contain other sublayers should give them unique names by adding a suffix to their own name, e.g. passing `name=f\"{name}/Linear_0\"` to their child. The `init_base_rng` should be forwarded to sublayers unchanged.\n",
    "- Layers that directly initialize parameters should use the helper function `pz.nn.make_parameter`, which implements the above logic and ensures parameters with different names are initialized differently, even with the same `init_base_rng`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7NRAVg1sCQC"
   },
   "source": [
    "### 6. Layers Use Named Axes (Via Lifted Positional Operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fw_Y1At_N5GM"
   },
   "source": [
    "Axis ordering can make it harder to reason about what complex models are doing, especially when trying to visualize or intervene on internal activations, or when using models from an unfamiliar codebase. It's often easier to refer to axes by name. But you shouldn't have to learn a whole new array API just to use named axes; the existing Numpy and JAX APIs are pretty good!\n",
    "\n",
    "Penzai strikes a middle ground using a lightweight *locally-positional* named-axis system, defined in a single file and with a minimal API surface. In short:\n",
    "\n",
    "- The `pz.nx.NamedArray` class wraps an ordinary array, and assigns each axis to either a position *or* a name (but not both).\n",
    "- You can convert positional axes to named ones using `.tag(...)`, or convert named axes back to positional axes using `.untag(...)`.\n",
    "- Any JAX function can be *lifted* using `pz.nx.nmap`. The lifted function will act normally over the positional axes but will be automatically vectorized over all of the named axes (using `jax.vmap` internally). Only `NamedArray` arguments are processed in this way; other arguments are just passed through.\n",
    "- Standard array methods and operators (e.g. `.sum()`, `+`, or slicing) are also lifted so that they operate over positional axes and vectorize over named axes.\n",
    "- By convention, Penzai layers use axis names to define their interface, but then use `.untag`, `nmap`, and `.tag` to implement their internal logic.\n",
    "\n",
    "For instance, here's how you might take a softmax over a vocabulary axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CQZaFJfCdzNW"
   },
   "outputs": [],
   "source": [
    "# Start with a JAX array:\n",
    "array = jax.random.normal(jax.random.key(0), [8, 32])\n",
    "# Wrap it as a named array:\n",
    "wrapped = pz.nx.wrap(array)\n",
    "# Assign names:\n",
    "named = wrapped.tag(\"batch\", \"vocabulary\")\n",
    "# Visualize it:\n",
    "named"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_XNvqhVReJ6Q"
   },
   "outputs": [],
   "source": [
    "# Un-tag the vocabulary axis:\n",
    "untagged = named.untag(\"vocabulary\")\n",
    "# Map the ordinary JAX softmax function over the temporary positional axis:\n",
    "softmaxed = pz.nx.nmap(jax.nn.softmax)(untagged, axis=0)\n",
    "# Tag the positional axis with a name again:\n",
    "softmaxed.tag(\"vocabulary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5X0GDqCXeq1o"
   },
   "source": [
    "And here's how you might wrap that in an idiomatic layer, which has a named-axis interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P_Tf4AMSeqjo"
   },
   "outputs": [],
   "source": [
    "@pz.pytree_dataclass\n",
    "class Softmax(pz.nn.Layer):\n",
    "  axis_name: str = dataclasses.field(metadata={\"pytree_node\": False})\n",
    "  def __call__(self, arg, **unused_side_inputs):\n",
    "    # Write the logic as if the argument is one dimensional:\n",
    "    arr = arg.untag(self.axis_name)\n",
    "    assert len(arr.positional_shape) == 1\n",
    "    result = pz.nx.nmap(jax.nn.softmax)(arr, axis=0)\n",
    "    # Then re-bind names at the end:\n",
    "    return result.tag(self.axis_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y6HZK0bwe_wo"
   },
   "outputs": [],
   "source": [
    "layer = Softmax(\"vocabulary\")\n",
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53T3Rt2VfB3o"
   },
   "outputs": [],
   "source": [
    "layer(named)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fAZDZ0IofJRS"
   },
   "source": [
    "Because everything vectorizes over names by default, Penzai models can usually be used with arbitrary numbers of batch axes at runtime as long as you give them unique names. You can even insert new layers that manipulate specific batch axes by name (e.g. copying activations from one input to another), without interfering with any of the shapes in the rest of your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Wy6X9jptLGy"
   },
   "source": [
    "## Putting It All Together: A Basic Penzai Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9QgMyqyHJrAt"
   },
   "source": [
    "To show how these principles interact, here's how we might implement a neural network from scratch in Penzai. We'll focus on re-implementing a basic MLP (like the running example above), and omit a few advanced features to keep things simple.\n",
    "\n",
    "An MLP is composed of a sequence of steps, including linear operations, biases, and elementwise activations. We can implement each of these using a separate layer so that we can manipulate them after the model is built, and define each using named axes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9iXn1WsUoQDr"
   },
   "outputs": [],
   "source": [
    "@pz.pytree_dataclass\n",
    "class SimpleLinear(pz.nn.Layer):\n",
    "  \"\"\"A simple linear layer with a single input/output axis.\"\"\"\n",
    "\n",
    "  # Parameters are annotated as `ParameterLike` to allow swapping them out after\n",
    "  # initialization.\n",
    "  kernel: pz.nn.ParameterLike[pz.nx.NamedArray]\n",
    "\n",
    "  # Non-Pytree fields (which are not arraylike) should be annotated as such to\n",
    "  # tell JAX not to try to convert them:\n",
    "  features_axis: str = dataclasses.field(metadata={\"pytree_node\": False})\n",
    "\n",
    "  def __call__(\n",
    "      self, x: pz.nx.NamedArray, /, **unused_side_inputs\n",
    "  ) -> pz.nx.NamedArray:\n",
    "    \"\"\"Multiplies the input by the learned kernel.\"\"\"\n",
    "    # pos_x has one positional axis\n",
    "    pos_x = x.untag(self.features_axis)\n",
    "    # pos_kernel has two positional axes\n",
    "    pos_kernel = self.kernel.value.untag(\"out_features\", \"in_features\")\n",
    "    # We can combine them using ordinary positional semantics:\n",
    "    pos_y = pz.nx.nmap(jnp.dot)(pos_kernel, pos_x)\n",
    "    return pos_y.tag(self.features_axis)\n",
    "\n",
    "  @classmethod\n",
    "  def from_config(\n",
    "      cls,\n",
    "      name: str,\n",
    "      init_base_rng: jax.Array | None,\n",
    "      in_features: int,\n",
    "      out_features: int,\n",
    "      features_axis: str = \"features\",\n",
    "  ) -> \"SimpleLinear\":\n",
    "    \"\"\"Constructs a linear layer from configuration arguments.\"\"\"\n",
    "    def _initializer(key):\n",
    "      arr = jax.nn.initializers.xavier_normal()(\n",
    "          key, (out_features, in_features)\n",
    "      )\n",
    "      return pz.nx.wrap(arr).tag(\"out_features\", \"in_features\")\n",
    "\n",
    "    return cls(\n",
    "        kernel=pz.nn.make_parameter(\n",
    "            name=f\"{name}.kernel\",\n",
    "            init_base_rng=init_base_rng,\n",
    "            initializer=_initializer,\n",
    "        ),\n",
    "        features_axis=features_axis,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wosqb7sPLrXb"
   },
   "outputs": [],
   "source": [
    "@pz.pytree_dataclass\n",
    "class SimpleBias(pz.nn.Layer):\n",
    "  \"\"\"A simple bias layer.\"\"\"\n",
    "  # The SimpleBias layer doesn't need to store its output axis name at all!\n",
    "  bias: pz.nn.ParameterLike[pz.nx.NamedArray]\n",
    "\n",
    "  def __call__(self, x: pz.nx.NamedArray, /, **unused_side_inputs) -> pz.nx.NamedArray:\n",
    "    \"\"\"Adds a bias to the input.\"\"\"\n",
    "    return x + self.bias.value  # Automatically vectorized!\n",
    "\n",
    "  @classmethod\n",
    "  def from_config(\n",
    "      cls,\n",
    "      name: str,\n",
    "      init_base_rng: jax.Array | None,\n",
    "      features: int,\n",
    "      features_axis: str = \"features\",\n",
    "  ) -> \"SimpleBias\":\n",
    "    \"\"\"Constructs a bias layer from configuration arguments.\"\"\"\n",
    "    return cls(\n",
    "        bias=pz.nn.make_parameter(\n",
    "            name=f\"{name}.bias\",\n",
    "            init_base_rng=init_base_rng,\n",
    "            initializer=lambda _: pz.nx.zeros({features_axis: features}),\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CxNeQRFbMQyw"
   },
   "outputs": [],
   "source": [
    "@pz.pytree_dataclass\n",
    "class SimpleElementwise(pz.nn.Layer):\n",
    "  \"\"\"A simple elementwise layer.\"\"\"\n",
    "  fn: Callable[[jax.Array], jax.Array] = dataclasses.field(\n",
    "      metadata={\"pytree_node\": False}\n",
    "  )\n",
    "\n",
    "  def __call__(self, x: pz.nx.NamedArray, /, **unused_side_inputs) -> pz.nx.NamedArray:\n",
    "    \"\"\"Runs the activation function.\"\"\"\n",
    "    return pz.nx.nmap(self.fn)(x)\n",
    "\n",
    "  # No need for `from_config`, since it would be the same as `__init__`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YsDgUw4M2rX"
   },
   "source": [
    "We can then define a top-level MLP layer as a subclass of `Sequential`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RYCIvpCoMdgd"
   },
   "outputs": [],
   "source": [
    "@pz.pytree_dataclass\n",
    "class SimpleMLP(pz.nn.Sequential):\n",
    "  # sublayers is inherited from Sequential, but we restate it here for clarity.\n",
    "  sublayers: list[pz.nn.Layer]\n",
    "\n",
    "  # __call__ is inherited from Sequential, so no need to reimplement it! In\n",
    "  # fact, Sequential.__call__ is marked with @typing.final so you don't\n",
    "  # accidentally override it.\n",
    "\n",
    "  @classmethod\n",
    "  def from_config(\n",
    "      cls,\n",
    "      name: str,\n",
    "      init_base_rng: jax.Array | None,\n",
    "      feature_sizes: Sequence[int],\n",
    "      activation: Callable[[jax.Array], jax.Array] = jax.nn.relu,\n",
    "      features_axis: str = \"features\",\n",
    "  ) -> \"SimpleMLP\":\n",
    "    \"\"\"Constructs a MLP with uninitialized parameters.\"\"\"\n",
    "    # We build the steps of the forward pass in from_config, and push all\n",
    "    # configuration arguments down to the sublayers:\n",
    "    sublayers = []\n",
    "    for i in range(len(feature_sizes) - 1):\n",
    "      # We need to ensure parameter name uniqueness ourselves:\n",
    "      sublayers.append(SimpleLinear.from_config(\n",
    "          name=f\"{name}/block_{i}/linear\",\n",
    "          init_base_rng=init_base_rng,\n",
    "          in_features=feature_sizes[i],\n",
    "          out_features=feature_sizes[i + 1],\n",
    "          features_axis=features_axis,\n",
    "      ))\n",
    "      sublayers.append(SimpleBias.from_config(\n",
    "          name=f\"{name}/block_{i}/bias\",\n",
    "          init_base_rng=init_base_rng,\n",
    "          features=feature_sizes[i + 1],\n",
    "          features_axis=features_axis,\n",
    "      ))\n",
    "      if i < len(feature_sizes) - 2:\n",
    "        sublayers.append(SimpleElementwise(activation))\n",
    "    return cls(sublayers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywlUUE7lRpmz"
   },
   "source": [
    "Building our model without an initialization PRNGKey just builds the structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cpj-xZ_cRpX9"
   },
   "outputs": [],
   "source": [
    "SimpleMLP.from_config(\n",
    "    name=\"mlp\",\n",
    "    init_base_rng=None,\n",
    "    feature_sizes=[8, 32, 32, 8],\n",
    "    activation=jax.nn.relu,\n",
    "    features_axis=\"features\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnxG5uUaP1t4"
   },
   "source": [
    "If we pass `init_base_rng`, it will also initialize the parameters as mutable Variable objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07sUUR6nP08u"
   },
   "outputs": [],
   "source": [
    "model = SimpleMLP.from_config(\n",
    "    name=\"mlp\",\n",
    "    init_base_rng=jax.random.key(42),\n",
    "    feature_sizes=[8, 32, 32, 8],\n",
    "    activation=jax.nn.relu,\n",
    "    features_axis=\"features\",\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OaDtl3fKQ_ev"
   },
   "source": [
    "We can call it with some example inputs to check that it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C3DcYQovQhlE"
   },
   "outputs": [],
   "source": [
    "model(pz.nx.ones({\"features\": 8}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "974BdsnwROWQ"
   },
   "source": [
    "Or set up a simple training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4EXbp28gR-W0"
   },
   "outputs": [],
   "source": [
    "from penzai.toolshed import basic_training\n",
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fwm_FMplRGz4"
   },
   "outputs": [],
   "source": [
    "example_inputs = pz.nx.wrap(\n",
    "    jax.random.normal(jax.random.key(100), (100, 8))\n",
    ").tag(\"batch\", \"features\")\n",
    "example_targets = pz.nx.wrap(\n",
    "    jax.random.normal(jax.random.key(101), (100, 8))\n",
    ").tag(\"batch\", \"features\")\n",
    "\n",
    "def loss_fn(model, rng, state, current_input, current_target):\n",
    "  del rng, state  # More complex training loops could use these if needed\n",
    "  model_out = model(current_input)\n",
    "  losses = pz.nx.nmap(jnp.square)(model_out - current_target)\n",
    "  loss = losses.untag(\"batch\", \"features\").unwrap().sum()\n",
    "  return (loss, None, {\"my_loss\": loss})\n",
    "\n",
    "trainer = basic_training.StatefulTrainer.build(\n",
    "    root_rng=jax.random.key(42),\n",
    "    model=model,\n",
    "    optimizer_def=optax.adam(0.01),\n",
    "    loss_fn=loss_fn,\n",
    ")\n",
    "\n",
    "outputs = []\n",
    "while trainer.state.value.step < 1000:\n",
    "  out = trainer.step(\n",
    "      current_input=example_inputs,\n",
    "      current_target=example_targets,\n",
    "  )\n",
    "  if trainer.state.value.step % 20 == 0:\n",
    "    print(f\"At {trainer.state.value.step}: {out}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_9ddvtxS4e_"
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77SPJBeSTNyE"
   },
   "source": [
    "You now know everything you need to get started with neural networks in Penzai!\n",
    "\n",
    "Penzai strives to enable complex modifications and interventions on models either before or after training them, without getting in your way. Following the principles described here is a recommended starting point and a great way to take advantage of all of Penzai's tooling, but it's not strictly enforced! You're free to use Penzai's visualization and patching tools with non-Penzai models, or define your own callable PyTree components without conforming to the `pz.nn.Layer` interface, if that makes more sense for your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-vxf05GD5fYO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "How to Think in Penzai",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
