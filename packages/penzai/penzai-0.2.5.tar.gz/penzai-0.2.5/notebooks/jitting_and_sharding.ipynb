{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfejMHs4lr8V"
   },
   "source": [
    "*Copyright 2024 The Penzai Authors.*\n",
    "\n",
    "*Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at*\n",
    "\n",
    "> http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "*Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or  implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USGIPdLYDzSo"
   },
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/google-deepmind/penzai/blob/main/notebooks/jitting_and_sharding.ipynb) [![Open in Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/google-deepmind/penzai/blob/main/notebooks/jitting_and_sharding.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qA3Q3cm5Cca9"
   },
   "source": [
    "# Jitting and Sharding Penzai Models\n",
    "\n",
    "Penzai works with JAX's standard function transformations, including JIT-compilation and array sharding. However, because Penzai includes support for mutable variables inside the model, some care must be taken to ensure you apply them in ways that JAX can understand!\n",
    "\n",
    "This notebook walks through some of the common aspects of JIT-compilation and sharding as they apply to Penzai tools and Penzai models. It assumes some basic familiarity with JAX's [JIT compilation](https://jax.readthedocs.io/en/latest/notebooks/thinking_in_jax.html) and [distributed array](https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html) systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHr2rnIL8DzM"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VkW4lYKAu-oR"
   },
   "source": [
    "Before we can get started in earnest, we need to set up the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ozG8ERNavDos"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmxgAcFQmZkB"
   },
   "source": [
    "To run this notebook, you need a Python environment with `penzai` and its dependencies installed.\n",
    "\n",
    "In Colab or Kaggle, you can install it using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XGZH58j8mPkj"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  import penzai\n",
    "except ImportError:\n",
    "  !pip install penzai[notebook]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iog3oMAMGCMG"
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v26wYYx6QSn3"
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Mh2mAuiQ4aa"
   },
   "outputs": [],
   "source": [
    "import treescope\n",
    "import penzai\n",
    "from penzai import pz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MQU6QfoZVYOL"
   },
   "outputs": [],
   "source": [
    "from penzai.models import transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGzhV5uWvkvB"
   },
   "source": [
    "### Setting up Penzai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjGkV8F8vmpi"
   },
   "source": [
    "For this tutorial, we'll enable [Treescope](https://treescope.readthedocs.io/en/stable/) (Penzai's companion pretty-printer) as the default IPython pretty-printer. This is recommended when using Penzai in an interactive environment. We'll also enable automatic array visualization, which also makes it easy to visualize array shardings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YodWk_jmva_7"
   },
   "outputs": [],
   "source": [
    "treescope.basic_interactive_setup(autovisualize_arrays=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8jaslw09Fn6t"
   },
   "source": [
    "We'll assume this notebook is running on a backend with eight devices. If needed, you can force JAX to treat the CPU backend as multiple devices using\n",
    "```python\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_force_host_platform_device_count=8\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tCiROtE5Fq53"
   },
   "outputs": [],
   "source": [
    "pz.show(jax.local_devices())\n",
    "assert jax.local_device_count() == 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20jyxs7mEAJj"
   },
   "source": [
    "## JIT-Compiling Penzai Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUc2cj5KGeWx"
   },
   "source": [
    "Penzai model objects themselves are always JAX PyTrees. However, in addition to arrays and arraylike leaves, Penzai models can also include two types of \"variable\" leaves: `pz.Parameter` and `pz.StateVariable`. These are currently not directly supported by `jax.jit`.\n",
    "\n",
    "For example, consider the following (somewhat contrived) model, which has a learnable parameter and an incrementing counter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kO4uNykhBglb"
   },
   "outputs": [],
   "source": [
    "@pz.pytree_dataclass\n",
    "class CounterLayer(pz.nn.Layer):\n",
    "  counter: pz.StateVariable[int]\n",
    "\n",
    "  def __call__(self, x, **_side_inputs):\n",
    "    self.counter.value += 1\n",
    "    return (x, self.counter.value)\n",
    "\n",
    "model = pz.nn.Sequential([\n",
    "    pz.nn.Linear.from_config(\n",
    "        name=\"linear\",\n",
    "        init_base_rng=jax.random.PRNGKey(0),\n",
    "        input_axes={\"features\": 8},\n",
    "        output_axes={\"features_out\": 8},\n",
    "    ),\n",
    "    CounterLayer(counter=pz.StateVariable(value=0, label=\"counter\")),\n",
    "])\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4RHdz1neB_bx"
   },
   "outputs": [],
   "source": [
    "model(pz.nx.ones({\"features\": 8}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wQMFw-ElCCrY"
   },
   "outputs": [],
   "source": [
    "model(pz.nx.ones({\"features\": 8}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uc0oqs43BZHa"
   },
   "source": [
    "To JIT-compile a Penzai model, you have three options:\n",
    "\n",
    "- The \"functional API\": A set of Penzai tools to help you manipulate variable states using pure functions and JAX PyTrees.\n",
    "- `pz.variable_jit`: A convenience wrapper around `jax.jit` that also works for PyTrees containing `pz.Parameter` and `pz.StateVariable`.\n",
    "- `toolshed.jit_wrapper.Jitted`: A model combinator that acts like an ordinary `Layer`, but always runs under `jax.jit` (using `pz.variable_jit` around its `__call__` method)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCdRQIYqg-rQ"
   },
   "source": [
    "### The \"Functional API\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QsvDFbK5hHTj"
   },
   "source": [
    "Each of Penzai's variables comes in three forms:\n",
    "\n",
    "- Mutable variables (`pz.Parameter` and `pz.StateVariable`), which are Python objects whose `.value` attribute can be modified freely,\n",
    "- Frozen variable values (`pz.ParameterValue` and `pz.StateVariableValue`), which are immutable JAX PyTree objects that are safe to pass through JAX transforms,\n",
    "- Variable slots (`pz.ParameterSlot` and `pz.StateVariableSlot`), which are empty placeholders that indicate locations of variables in a larger tree.\n",
    "\n",
    "For full control over JIT compilation, you can manually convert variables from their mutable form to their immutable form when crossing JAX transform boundaries. The relevant functions:\n",
    "\n",
    "- `pz.unbind_variables` (and type-specific variants `pz.unbind_params` and `pz.unbind_state_vars`): Extracts and deduplicates variables, returning a tree of variable slots along with the deduplicated variables.\n",
    "- `pz.bind_variables`: Re-inserts variables into variable slots.\n",
    "- `Parameter.freeze()` and `StateVariable.freeze()`: Converts a mutable variable into an immutable value.\n",
    "- `ParameterValue.unfreeze_as_copy()` and `StateVariableValue.unfreeze_as_copy()`: Converts an immutable value back into a (new) mutable variable.\n",
    "\n",
    "For instance, for our example model above, we can use `pz.unbind_variables` and `.freeze()` to extract the mutable parts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5taD64esA5XP"
   },
   "outputs": [],
   "source": [
    "model_with_slots, all_vars = pz.unbind_variables(model)\n",
    "pz.show(\"model_with_slots:\", model_with_slots)\n",
    "pz.show(\"all_vars:\", all_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DjXSw2bBChTK"
   },
   "outputs": [],
   "source": [
    "frozen_vars = [var.freeze() for var in all_vars]\n",
    "pz.show(\"frozen_vars:\", frozen_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0S3Pv5CFCmZh"
   },
   "source": [
    "We can then define a pure function that re-binds these variables, and call it under `jax.jit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BVSPAG-2CmEj"
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def rebinding_call(model_with_slots, frozen_vars, arg):\n",
    "  # Make temporary mutable copies:\n",
    "  new_vars = [var.unfreeze_as_copy() for var in frozen_vars]\n",
    "  # Re-attach them to the model:\n",
    "  model = pz.bind_variables(model_with_slots, new_vars)\n",
    "  # Run it:\n",
    "  result = model(arg)\n",
    "  # Extract and re-freeze the variables:\n",
    "  refrozen_vars = [var.freeze() for var in new_vars]\n",
    "  return result, refrozen_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EwM-uNEvDEYU"
   },
   "outputs": [],
   "source": [
    "result, new_frozen_vars = rebinding_call(\n",
    "    model_with_slots, frozen_vars, pz.nx.ones({\"features\": 8})\n",
    ")\n",
    "pz.show(\"result:\", result)\n",
    "pz.show(\"new_frozen_vars:\", new_frozen_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CUHxZs9IDq4F"
   },
   "source": [
    "We can then update the old variables with their new values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wClJAgYxDz0S"
   },
   "outputs": [],
   "source": [
    "for var, new_value in zip(all_vars, new_frozen_vars):\n",
    "  var.update(new_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PgjwVN-oDLw3"
   },
   "source": [
    "To make this a bit less verbose, `pz.nn.Layer` has a method `.stateless_call(vars, ...)` that makes temporary mutable copies of its input variables, like `rebinding_call`. So, we could have equivalently written the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EmkmyV6TDlzE"
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def rebinding_call_2(model_with_slots, frozen_vars, arg):\n",
    "  result, refrozen_vars = model_with_slots.stateless_call(frozen_vars, arg)\n",
    "  return result, refrozen_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v_H6RMm9EE5L"
   },
   "outputs": [],
   "source": [
    "result, new_frozen_vars = rebinding_call_2(\n",
    "    model_with_slots, frozen_vars, pz.nx.ones({\"features\": 8})\n",
    ")\n",
    "pz.show(\"result:\", result)\n",
    "pz.show(\"new_frozen_vars:\", new_frozen_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5_zY-QiEOKQ"
   },
   "source": [
    "If you want to JIT-compile your model initializer, you can do this using the functional API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rvuV-QBnEddA"
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def functional_init(init_base_rng):\n",
    "  model = pz.nn.Sequential([\n",
    "      pz.nn.Linear.from_config(\n",
    "          name=\"linear\",\n",
    "          init_base_rng=init_base_rng,\n",
    "          input_axes={\"features\": 8},\n",
    "          output_axes={\"features_out\": 8},\n",
    "      ),\n",
    "      CounterLayer(counter=pz.StateVariable(value=0, label=\"counter\")),\n",
    "  ])\n",
    "  # Unbind and also freeze all variables:\n",
    "  return pz.unbind_variables(model, freeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CgbI9GE2EtTH"
   },
   "outputs": [],
   "source": [
    "model_with_slots, init_var_values = functional_init(jax.random.PRNGKey(0))\n",
    "# Re-bind variables and also make them mutable again:\n",
    "model = pz.bind_variables(\n",
    "    model_with_slots, init_var_values, unfreeze_as_copy=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4_hGJz4vE5LI"
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYMPH1mrhIRC"
   },
   "source": [
    "### `pz.variable_jit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ng6ey8xthKpD"
   },
   "source": [
    "If you don't want to use the functional API directly, you can instead use `pz.variable_jit`, which is a wrapper around `jax.jit` that allows the function arguments to contain `pz.Parameter` and `pz.StateVariable` in addition to arrays, and handles updating their values for you. For instance, you could write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ysHu-koOF54I"
   },
   "outputs": [],
   "source": [
    "@pz.variable_jit\n",
    "def jitted_call(model, arg):\n",
    "  return model(arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yBXpp9OwGJ54"
   },
   "outputs": [],
   "source": [
    "jitted_call(model, pz.nx.ones({\"features\": 8}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1TfJx0bcGMN9"
   },
   "outputs": [],
   "source": [
    "jitted_call(model, pz.nx.ones({\"features\": 8}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IlWHNttGPXx"
   },
   "source": [
    "Note that `pz.variable_jit` does not support returning variables from the jitted computation, so it can't be used to JIT-compile model initialization. It also does not support \"closing over\" global references to variable objects defined outside of the function. Every variable used by the function inside `pz.variable_jit` must have been passed in as an input argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUROW9BVhLUz"
   },
   "source": [
    "### `jit_wrapper.Jitted`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJGserZyhN7L"
   },
   "source": [
    "`pz.variable_jit` works for top-level functions, but sometimes you may want to JIT-compile a specific part of a Penzai model, or compile the forward pass without having to use an indirect `jitted_call` function. For this purpose, Penzai provides a layer wrapper `Jitted` in `penzai.toolshed.jit_wrapper`, which JIT-compiles its forward pass when called.\n",
    "\n",
    "To use it, you can simply wrap your model in `jit_wrappers.Jitted` and then call it as normal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jZQKzEl9IHVm"
   },
   "outputs": [],
   "source": [
    "from penzai.toolshed import jit_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8e4MeZYqIFcS"
   },
   "outputs": [],
   "source": [
    "jit_model = jit_wrapper.Jitted(model)\n",
    "jit_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FqrsajDHIRn-"
   },
   "outputs": [],
   "source": [
    "jit_model(pz.nx.ones({\"features\": 8}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxRhcC0LITQe"
   },
   "source": [
    "You can also insert `Jitted` around any sublayer of the model, e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FWmZMsZvITFB"
   },
   "outputs": [],
   "source": [
    "jit_model_2 = (\n",
    "    pz.select(model)\n",
    "    .at_instances_of(pz.nn.Linear | CounterLayer)\n",
    "    .apply(jit_wrapper.Jitted)\n",
    ")\n",
    "jit_model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vjOrzXZTInJE"
   },
   "outputs": [],
   "source": [
    "jit_model_2(pz.nx.ones({\"features\": 8}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnbd8W_jIsLY"
   },
   "source": [
    "Note that the `Jitted` wrapper is just an ordinary Penzai layer, and you can still pull back out the original model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q625qRNwI_GA"
   },
   "outputs": [],
   "source": [
    "jit_model.body == model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZZag_0nEOIB"
   },
   "source": [
    "## Sharding Basics, and Visualizing Shardings with Treescope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q18ckhsWMk7A"
   },
   "source": [
    "Penzai's array autovisualizer supports showing shardings and sharded arrays by default. This section explains the basics of JAX's distributed array shardings and how you can visualize the different components in Treescope. (See [this page](https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html) for the official documentation of JAX's sharding system.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CMTVux7AQiTj"
   },
   "source": [
    "### Positional shardings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ypez_YTWNMPp"
   },
   "source": [
    "At a high level, you can think of a \"sharding\" as a multidimensional array of device objects, which will be matched with your multidimensional array of data to determine which part of the array ends up on each device. You generally build a sharding by starting with a NumPy array of devices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DB7ywoGRNL1e"
   },
   "outputs": [],
   "source": [
    "from jax.experimental import mesh_utils\n",
    "devices = mesh_utils.create_device_mesh((8,))\n",
    "devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A0BXLtlANv2O"
   },
   "source": [
    "A simple type of sharding is `PositionalSharding`, which essentially just holds onto these devices and tracks some extra JAX-specific information. If you print out a `PositionalSharding` in Treescope, it color-codes the devices and shows you their arrangement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s3MesweYOqK2"
   },
   "outputs": [],
   "source": [
    "pos_sharding = jax.sharding.PositionalSharding(devices)\n",
    "pos_sharding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EeuoOlsbO5uI"
   },
   "source": [
    "In this case, the sharding has a single positional axis, of length 8. We can use this to shard arrays whose (first) positional axis is a multiple of 8. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "05EglsLbPGo0"
   },
   "outputs": [],
   "source": [
    "jax.device_put(jnp.ones(16), pos_sharding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7p19KDEPvxC"
   },
   "source": [
    "You can click the \"Sharded across 8 TPU devices\" message to show a visualization of the sharding for this array. When automatic array visualization is enabled, sharding visualizations are automatically added to any array that is sharded or replicated.\n",
    "\n",
    "We can reshape positional shardings to give them multiple axes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Sr8cdyIQDni"
   },
   "outputs": [],
   "source": [
    "pos_sharding.reshape((4,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6YU8KrbCQGZl"
   },
   "outputs": [],
   "source": [
    "jax.device_put(jnp.ones([8, 8]), pos_sharding.reshape((4,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8U7Tf7drQRSx"
   },
   "source": [
    "If you expand the sharding visualization above, you'll see how the two axes of the array are matched with the two axes of the sharding.\n",
    "\n",
    "You can also use shardings to indicate that certain parts of the array should be *replicated* on multiple devices, using `replicate`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wiQImi8HQ2eJ"
   },
   "outputs": [],
   "source": [
    "pos_sharding.reshape((2, 4)).replicate(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xSp4rCrnQ_Be"
   },
   "outputs": [],
   "source": [
    "jax.device_put(jnp.ones([8, 8]), pos_sharding.reshape((2, 4)).replicate(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytz-yk_mRD-o"
   },
   "source": [
    "Each element of an array with a replicated sharding will appear on more than one device. This is visually represented in Treescope using a multicolored pattern.\n",
    "\n",
    "You can also fully-replicate the array over all of the devices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OFr1_cLHRDuS"
   },
   "outputs": [],
   "source": [
    "pos_sharding.replicate(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ofc7QkjDRd9O"
   },
   "outputs": [],
   "source": [
    "jax.device_put(jnp.ones([8, 8]), pos_sharding.replicate(axis=0).reshape((1, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqvmCFxCRh_f"
   },
   "source": [
    "Fully-replicated arrays are also identified as such in the sharding summary before being expanded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XzWSqgC5Qjqj"
   },
   "source": [
    "### Meshes and named shardings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2iGPexZqQpS_"
   },
   "source": [
    "It is often convenient to refer to different axes of an array of devices by name instead of by position. JAX represents this using the type `jax.sharding.Mesh`. Conceptually, just as a `PositionalSharding` is essentially a positional array of devices, a `Mesh` is essentially a named array of devices, i.e. an array of devices where each axis has a name.\n",
    "\n",
    "Penzai annotates the device ID arrays of `Mesh` instances with axis names instead of axis positions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2MZOKGzASnlC"
   },
   "outputs": [],
   "source": [
    "mesh = jax.sharding.Mesh(devices.reshape((4, 2)), axis_names=('foo', 'bar'))\n",
    "mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsytkAohS9m5"
   },
   "source": [
    "To shard a (positionally-indexed) JAX array using a mesh, you can use `jax.sharding.NamedSharding` to assign particular axis indices to mesh axis names, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y18TEPOOTMLe"
   },
   "outputs": [],
   "source": [
    "jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec('foo', 'bar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oiv6nIo4TRxW"
   },
   "outputs": [],
   "source": [
    "jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(None, ('bar', 'foo'), None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i3Op7-ThTcDM"
   },
   "outputs": [],
   "source": [
    "jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec('foo'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eQMhXnwZTgjV"
   },
   "source": [
    "Note: Each `NamedSharding` specifies how to shard an input array's *positional axes*, since ordinary JAX arrays only have positional axes. The names in the `NamedSharding` are just a way to match the positional axes in the array with the corresponding names in the `Mesh`. For this reason, visualizations of `NamedSharding` instances are annotated with positional axes, not axis names.\n",
    "\n",
    "(Penzai already has its own mechanism for binding names to an array's positional axes: `pz.nx.NamedArray`. We'll discuss how to shard Penzai's `NamedArray` next.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPTKsWLVFMQd"
   },
   "source": [
    "## Sharding Penzai's NamedArrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skkgyBErYqdi"
   },
   "source": [
    "### Manually sharding NamedArrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CMa5pJt3U7aN"
   },
   "source": [
    "Fundamentally, there are no changes when applying JAX shardings to Penzai's `NamedArray`s. Internally, a `NamedArray` is just a dataclass PyTree node that contains a JAX array and some axis name annotations, which we can see if we disable automatic array visualization temporarily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p4AMqgEOVVk5"
   },
   "outputs": [],
   "source": [
    "arr = pz.nx.arange(\"foo\", 1, 4) + pz.nx.arange(\"bar\", 0, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iR_e_twSVOCh"
   },
   "outputs": [],
   "source": [
    "# With automatic array visualization enabled:\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bonDVqA2Vgap"
   },
   "outputs": [],
   "source": [
    "%%autovisualize None\n",
    "# ^ With automatic array visualization disabled (and expanding it to show detail)\n",
    "pz.select(arr).at_instances_of(jax.Array).show_value()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fh5lL50fVuJj"
   },
   "source": [
    "JAX's sharding system allows you to specify the sharding for a PyTree of arrays by using a matching PyTree of shardings. So, we can build a sharding for this named array by inserting a positional sharding into it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K2eQvh_AV4e4"
   },
   "outputs": [],
   "source": [
    "data_array_sharding = jax.sharding.PositionalSharding(devices).reshape((2,4)).replicate(axis=0)\n",
    "sharding_for_arr = pz.nx.NamedArray(\n",
    "    named_axes=arr.named_axes,\n",
    "    data_array=data_array_sharding,\n",
    ")\n",
    "sharding_for_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yh0usyDpXDPj"
   },
   "source": [
    "Applying this sharding to the NamedArray shards the `data_array` attribute (try expanding below):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ADT9myFsXYCf"
   },
   "outputs": [],
   "source": [
    "%%autovisualize lambda a,p: treescope.ArrayAutovisualizer()(a, p) if isinstance(a, jax.Array) else None\n",
    "# (^ this line overrides the autovisualizer to show the sharding of the data array when expanded)\n",
    "\n",
    "sharded_arr = jax.device_put(arr, sharding_for_arr)\n",
    "pz.select(sharded_arr).at_instances_of(jax.Array).show_value()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPa-auHeYMvX"
   },
   "source": [
    "But with normal automatic array visualization, treescope will show you how the *named* axes are sharded, since that's usually what you care about when using Penzai models in practice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HadvQnuvYWJr"
   },
   "outputs": [],
   "source": [
    "sharded_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nlf0vWOCYuh0"
   },
   "source": [
    "### Automatically building shardings for NamedArrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Hy8_V9QYw6x"
   },
   "source": [
    "To simplify this process, Penzai provides some optional utilities for constructing shardings for `NamedArray` instances. These utilities take a `Mesh`, and allow you to map from `NamedArray` axis names to `Mesh` axis names across a tree of arrays.\n",
    "\n",
    "For instance, consider this tree of arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rBf0KIpqZoLu"
   },
   "outputs": [],
   "source": [
    "some_array_tree = {\n",
    "    \"one\": pz.nx.ones({\"a\": 4, \"b\": 8, \"c\": 6}),\n",
    "    \"two\": pz.nx.ones({\"a\": 8}),\n",
    "    \"three\": pz.nx.ones({\"b\": 4, \"d\": 12}),\n",
    "}\n",
    "some_array_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SgrBL4fRaAb3"
   },
   "source": [
    "And this mesh:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MaDfIMbtaC7-"
   },
   "outputs": [],
   "source": [
    "mesh = jax.sharding.Mesh(devices.reshape((4, 2)), axis_names=('foo', 'bar'))\n",
    "mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIRFBn_uaHdg"
   },
   "source": [
    "We can assign each named axis in `some_array_tree` to an axis in the mesh using the `name_to_name_sharding` utility, which builds a tree of shardings that is compatible with the tree of arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JwKu52ifaG8K"
   },
   "outputs": [],
   "source": [
    "from penzai.toolshed import sharding_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JY_DUvaAaSXu"
   },
   "outputs": [],
   "source": [
    "shardings = sharding_util.name_to_name_sharding(\n",
    "    some_array_tree,\n",
    "    mesh,\n",
    "    axis_name_to_mesh_name={\n",
    "        \"a\": \"bar\",\n",
    "        \"b\": \"foo\",\n",
    "    },\n",
    ")\n",
    "shardings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NTBicKeLafVB"
   },
   "source": [
    "We can then apply those shardings to the original array tree to shard the corresponding axes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SAWE43sHan04"
   },
   "outputs": [],
   "source": [
    "jax.device_put(some_array_tree, shardings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xIDPTi3a-Mi"
   },
   "source": [
    "Even simpler, if you just want to call `device_put` you can bundle them into one call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Blvw8lo_bE2U"
   },
   "outputs": [],
   "source": [
    "sharding_util.name_to_name_device_put(\n",
    "    some_array_tree,\n",
    "    mesh,\n",
    "    axis_name_to_mesh_name={\n",
    "        \"a\": \"bar\",\n",
    "        \"b\": \"foo\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M23P_pPCbKqW"
   },
   "source": [
    "If your mesh happens to use the exact same axis names as your arrays, you don't need the `axis_name_to_mesh_name` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XjoV48jAbRLT"
   },
   "outputs": [],
   "source": [
    "already_matching_mesh = jax.sharding.Mesh(devices.reshape((4, 2)), axis_names=('b', 'a'))\n",
    "sharding_util.name_to_name_device_put(\n",
    "    some_array_tree,\n",
    "    already_matching_mesh,\n",
    "    # axis_name_to_mesh_name inferred as {\"a\":\"a\", \"b\":\"b\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORHLiG38FQ-b"
   },
   "source": [
    "## Sharding Penzai Models and Training Loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tYza3pi1cB8r"
   },
   "source": [
    "Penzai also provides some utilities that are specific to training and using Penzai neural newtork models. These are simple self-contained utilities that can be a good starting point, but you are free to customize them to get lower-level control when needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CBCz_sOQZDoJ"
   },
   "source": [
    "### Sharding Parameter Initializers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xo8KALJocV9F"
   },
   "source": [
    "If you already know the shardings for your model parameters, you can pass those, you can JIT-compile parameter optimization using something like\n",
    "\n",
    "```python\n",
    "def functional_init(init_base_rng):\n",
    "  model = ...\n",
    "  return pz.unbind_variables(model, freeze=True)\n",
    "\n",
    "sharded_init = jax.jit(\n",
    "  functional_init,\n",
    "  out_shardings=..., # <- insert your desired sharding specification here\n",
    ")\n",
    "\n",
    "model = pz.bind_variables(*sharded_init(rng))\n",
    "```\n",
    "\n",
    "If you want to infer `out_shardings` using the axis names of your parameters, you can do that using the helper function `sharding_util.sharded_init`. This function just traces the initializer to figure out the parameter shapes, infers the right sharding to use, and then runs your initializer accordingly.\n",
    "\n",
    "For instance, here's how you could initialize the parameters of a small transformer in a sharded way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pPaUvWMIeV3O"
   },
   "outputs": [],
   "source": [
    "from penzai.toolshed import sharding_util\n",
    "from penzai.models.transformer.variants import llamalike_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wuVT7l-Aa-Lk"
   },
   "outputs": [],
   "source": [
    "# Very small transformer config, for demo purposes\n",
    "config = llamalike_common.LlamalikeTransformerConfig(\n",
    "    num_kv_heads=2,\n",
    "    query_head_multiplier=1,\n",
    "    embedding_dim=64,\n",
    "    projection_dim=16,\n",
    "    mlp_hidden_dim=128,\n",
    "    num_decoder_blocks=2,\n",
    "    vocab_size=100,\n",
    "    mlp_variant=\"geglu_approx\",\n",
    "    rope_wavelength=10_000,\n",
    "    tie_embedder_and_logits=True,\n",
    "    use_layer_stack=False,\n",
    "    parameter_dtype=jnp.float32,\n",
    "    activation_dtype=jnp.float32,\n",
    ")\n",
    "\n",
    "tiny_transformer = sharding_util.sharded_init(\n",
    "    llamalike_common.build_llamalike_transformer,\n",
    "    config=config,\n",
    "    init_base_rng=jax.random.key(42),\n",
    "    mesh=jax.sharding.Mesh(devices, axis_names=('devices',)),\n",
    "    axis_name_to_mesh_name={\n",
    "        # Shard the embedding dimension across devices.\n",
    "        \"embedding\": \"devices\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0NOvdTWGcniz"
   },
   "outputs": [],
   "source": [
    "tiny_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pRJYY-p_FVNj"
   },
   "source": [
    "### Sharding Model Training and Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XoToh1lfsRz"
   },
   "source": [
    "Once you've sharded your parameters, you usually don't have to do anything special to enable device-parallel computation when training or running a model. This is because JAX can automatically propagate and infer array sharding information. (See JAX's documentation on [automatic parallelization](https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html)!)\n",
    "\n",
    "For instance, we can call our sharded model with a sharded input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5pqGGCdVg_Ir"
   },
   "outputs": [],
   "source": [
    "tokens = sharding_util.name_to_name_device_put(\n",
    "    pz.nx.ones({\"batch\": 16, \"seq\": 20}, dtype=jnp.int32),\n",
    "    mesh=jax.sharding.Mesh(devices, axis_names=('devices',)),\n",
    "    axis_name_to_mesh_name={\"batch\": \"devices\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8eIv5RumhO5G"
   },
   "outputs": [],
   "source": [
    "result = tiny_transformer(tokens)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CF5J5WDVh6Lu"
   },
   "source": [
    "The result in this case will usually be sharded also over the batch axis, which means JAX automatically chose a \"fully sharded data parallel\" (FSDP) sharding for our computation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WHY82E1ziDuM"
   },
   "outputs": [],
   "source": [
    "treescope.render_array_sharding(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3C9l6Qjxg5Yj"
   },
   "source": [
    "\n",
    "If you need more direct control, you can use the `in_shardings` and `out_shardings` arguments of `jax.jit` in combination with the \"Functional API\" for Penzai's parameters and state variables, described above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpLaUQbCFhDM"
   },
   "source": [
    "### Adding Sharding Constraints to Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U59lObkMff19"
   },
   "source": [
    "You may want more control over the way that intermediate values are sharded. JAX allows you to control this using `jax.lax.with_sharding_constraint`, which forces a particular value to have a particular sharding.\n",
    "\n",
    "In a Penzai model, sharding constraints can be enforced by simply inserting new layers into the model at the points where you want to constrain the shardings. Penzai's `sharding_util` module provides two simple classes `ConstrainSharding` and `ConstrainShardingByName` for this purpose, defined as\n",
    "```python\n",
    "@pz.pytree_dataclass\n",
    "class ConstrainSharding(pz.nn.Layer):\n",
    "  sharding: PyTreeOfShardings = field(metadata={\"pytree_node\": False})\n",
    "  def __call__(self, tree: Any, **_unused_side_inputs) -> Any:\n",
    "    return jax.lax.with_sharding_constraint(tree, self.sharding)\n",
    "\n",
    "@pz.pytree_dataclass\n",
    "class ConstrainShardingByName(pz.nn.Layer):\n",
    "  mesh: jax.sharding.Mesh = field(metadata={\"pytree_node\": False})\n",
    "  axis_name_to_mesh_name: dict[str, str | tuple[str, ...]] | None = (\n",
    "      field(default=None, metadata={\"pytree_node\": False})\n",
    "  )\n",
    "  def __call__(self, tree: PyTreeOfNamedArrays, **_unused_side_inputs) -> PyTreeOfNamedArrays:\n",
    "    return jax.lax.with_sharding_constraint(\n",
    "        tree,\n",
    "        name_to_name_sharding(tree, self.mesh, self.axis_name_to_mesh_name),\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1fu1Z4dgUCm"
   },
   "source": [
    "You can insert them into the model using logic like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-PASk2ADibdy"
   },
   "outputs": [],
   "source": [
    "mesh = jax.sharding.Mesh(devices, axis_names=('devices',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LUlJkzj-ZGcV"
   },
   "outputs": [],
   "source": [
    "# Make sure it's sharded over the batch axis after each block.\n",
    "tiny_transformer_constrained = (\n",
    "    pz.select(tiny_transformer)\n",
    "    .at_instances_of(transformer.model_parts.TransformerBlock)\n",
    "    .insert_after(sharding_util.ConstrainShardingByName(\n",
    "        mesh, axis_name_to_mesh_name={\"batch\": \"devices\"}\n",
    "    ))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vwxBq9TfqY7d"
   },
   "outputs": [],
   "source": [
    "# Visualize the constraints:\n",
    "pz.select(tiny_transformer_constrained).at_instances_of(sharding_util.ConstrainShardingByName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-KzB-r6gXVj"
   },
   "source": [
    "This gives you a version of the model whose intermediates will always be sharded in the way you specified.\n",
    "\n",
    "If you later want to change how your model's intermediates are sharded, you can simply remove these constraints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p_RP3QEKgrNK"
   },
   "outputs": [],
   "source": [
    "tiny_transformer_unconstrained = (\n",
    "    pz.select(tiny_transformer_constrained)\n",
    "    .at_instances_of(sharding_util.ConstrainShardingByName)\n",
    "    .remove_from_parent()\n",
    ")\n",
    "\n",
    "# No more constraints:\n",
    "(\n",
    "    pz.select(tiny_transformer_unconstrained)\n",
    "    .at_instances_of(sharding_util.ConstrainShardingByName)\n",
    "    .assert_count_is(0)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Jitting and Sharding Penzai Models",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
